<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 6 Hierarchical generalization | Computational Psychology in Python</title>
<meta name="author" content="Alan Jern">
<meta name="description" content="In previous examples, there were always a finite number of hypotheses that we were making inferences about (number of black balls, fair or trick coin, yellow or green taxi). Sometimes, we want to...">
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content="Chapter 6 Hierarchical generalization | Computational Psychology in Python">
<meta property="og:type" content="book">
<meta property="og:description" content="In previous examples, there were always a finite number of hypotheses that we were making inferences about (number of black balls, fair or trick coin, yellow or green taxi). Sometimes, we want to...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 6 Hierarchical generalization | Computational Psychology in Python">
<meta name="twitter:description" content="In previous examples, there were always a finite number of hypotheses that we were making inferences about (number of black balls, fair or trick coin, yellow or green taxi). Sometimes, we want to...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.9/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Computational Psychology in Python</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Preface</a></li>
<li><a class="" href="intro.html"><span class="header-section-number">2</span> Why computational modeling?</a></li>
<li><a class="" href="bayes.html"><span class="header-section-number">3</span> Bayesian inference</a></li>
<li><a class="" href="generalization.html"><span class="header-section-number">4</span> Generalization</a></li>
<li><a class="" href="categorization.html"><span class="header-section-number">5</span> Categorization</a></li>
<li><a class="active" href="hierarchical-generalization.html"><span class="header-section-number">6</span> Hierarchical generalization</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="hierarchical-generalization" class="section level1" number="6">
<h1>
<span class="header-section-number">6</span> Hierarchical generalization<a class="anchor" aria-label="anchor" href="#hierarchical-generalization"><i class="fas fa-link"></i></a>
</h1>
<p>In <a href="@ref%7B#bayes%7D">previous examples</a>, there were always a finite number of hypotheses that we were making inferences about (number of black balls, fair or trick coin, yellow or green taxi). Sometimes, we want to consider an infinite set of hypotheses. For example, after flipping a coin, what is the probability of that coin coming up heads? The answer to this question could be any number in the interval [0,1].</p>
<div id="the-beta-binomial-model" class="section level2" number="6.1">
<h2>
<span class="header-section-number">6.1</span> The Beta-Binomial model ü™ô<a class="anchor" aria-label="anchor" href="#the-beta-binomial-model"><i class="fas fa-link"></i></a>
</h2>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-53"></span>
<img src="images/05/coin-in-hand.jpg" alt="Photo by ZSun Fu on Unsplash." width="75%"><p class="caption">
Figure 6.1: Photo by ZSun Fu on Unsplash.
</p>
</div>
<p>We can answer this question with a model called the Beta-Binomial model, named for the probability distributions it uses. First, let‚Äôs set up the basic assumptions of the model.</p>
<p>Let <span class="math inline">\(P(\text{heads}) = \theta\)</span>. We don‚Äôt know what <span class="math inline">\(\theta\)</span> is. After observing a sequence of coin flips <span class="math inline">\(D\)</span>, we want to estimate <span class="math inline">\(\theta\)</span>. This can be accomplished by directly applying Bayes‚Äôs rule:</p>
<p><span class="math display">\[
P(\theta|D) = \frac{P(D|\theta) P(\theta)}{P(D)}
\]</span></p>
<p>The data <span class="math inline">\(D\)</span> in this case corresponds to the number of <span class="math inline">\(k\)</span> heads out of <span class="math inline">\(n\)</span> total flips. This follows a <a href="https://en.wikipedia.org/wiki/Binomial_distribution">Binomial distribution</a>, which describes the probability of getting <span class="math inline">\(k\)</span> successes out of <span class="math inline">\(n\)</span> trials, when the probability of success on each trial is <span class="math inline">\(\theta\)</span>. We will define heads as a ‚Äúsuccess.‚Äù</p>
<p><span class="math display">\[
\begin{align}
P(d|\theta) = P(k|\theta,n) &amp;= \text{Bin}(k; n, \theta) \\
&amp;= \binom{n}{k} \theta^{k} (1-\theta)^{n-k}
\end{align}
\]</span></p>
<p>The notation for the <span class="math inline">\(\text{Bin}(\cdot)\)</span> function indicates that this is a distribution over <span class="math inline">\(k\)</span> (number of successes) and the distribution has the parameters <span class="math inline">\(n\)</span> (the total number of trials) and <span class="math inline">\(\theta\)</span> (the probability of a success on each trial).</p>
<p>We can define the prior, <span class="math inline">\(P(\theta)\)</span>, however we like. Because <span class="math inline">\(\theta\)</span> is a random variable that can take on any value from 0 to 1, we cannot just say <span class="math inline">\(P(\theta) = 0.5\)</span> like we could in earlier examples. Instead, <span class="math inline">\(P(\theta)\)</span> must be a probability distribution that assigns probabilities to any value from 0 to 1. If we know nothing about <span class="math inline">\(\theta\)</span>, we could use a Uniform(<span class="math inline">\([0,1]\)</span>) or non-informative prior that assigns equal probability to all values of <span class="math inline">\(\theta\)</span>.</p>
<p>Alternatively, a convenient choice (for reasons explained below) for <span class="math inline">\(P(\theta)\)</span> is the Beta distribution:</p>
<p><span class="math display">\[
P(\theta) = \text{Beta}(\theta;\alpha,\beta)
\]</span></p>
<p>The <a href="https://en.wikipedia.org/wiki/Beta_distribution">Beta distribution</a> has two parameters: <span class="math inline">\(\alpha &gt; 0\)</span> and <span class="math inline">\(\beta &gt; 0\)</span>. Let‚Äôs create a function that will allow us to visualize the Beta distribution.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="hierarchical-generalization.html#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb58-2"><a href="hierarchical-generalization.html#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb58-3"><a href="hierarchical-generalization.html#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb58-4"><a href="hierarchical-generalization.html#cb58-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-5"><a href="hierarchical-generalization.html#cb58-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_beta(a, b):</span>
<span id="cb58-6"><a href="hierarchical-generalization.html#cb58-6" aria-hidden="true" tabindex="-1"></a>  x <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="dv">1</span>,num<span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb58-7"><a href="hierarchical-generalization.html#cb58-7" aria-hidden="true" tabindex="-1"></a>  px <span class="op">=</span> stats.beta.pdf(x, a, b)</span>
<span id="cb58-8"><a href="hierarchical-generalization.html#cb58-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb58-9"><a href="hierarchical-generalization.html#cb58-9" aria-hidden="true" tabindex="-1"></a>  fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb58-10"><a href="hierarchical-generalization.html#cb58-10" aria-hidden="true" tabindex="-1"></a>  ax.plot(x, px)</span>
<span id="cb58-11"><a href="hierarchical-generalization.html#cb58-11" aria-hidden="true" tabindex="-1"></a>  plt.show()</span></code></pre></div>
<p><code>plot_beta</code> takes two arguments: <code>a</code> (<span class="math inline">\(\alpha\)</span>), and <code>b</code>(<span class="math inline">\(\beta\)</span>) and plots a Beta distribution with those parameter values.</p>
<p>Let‚Äôs see what it looks like with a few different values.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="hierarchical-generalization.html#cb59-1" aria-hidden="true" tabindex="-1"></a>plot_beta(<span class="dv">1</span>,<span class="dv">1</span>)</span></code></pre></div>
<div class="inline-figure"><img src="_main_files/figure-html/unnamed-chunk-55-1.png" width="672"></div>
<p>When <span class="math inline">\(\alpha = \beta = 1\)</span>, the Beta distribution is identical to a Uniform(<span class="math inline">\([0,1]\)</span>) distribution.</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="hierarchical-generalization.html#cb60-1" aria-hidden="true" tabindex="-1"></a>plot_beta(<span class="dv">3</span>,<span class="dv">3</span>)</span></code></pre></div>
<div class="inline-figure"><img src="_main_files/figure-html/unnamed-chunk-56-3.png" width="672"></div>
<p>When <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are greater than 1 and equal, we get a distribution with a peak around 0.5. If we had strong prior expectations that the coin was unbiased, we could increase the parameters even more:</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="hierarchical-generalization.html#cb61-1" aria-hidden="true" tabindex="-1"></a>plot_beta(<span class="dv">50</span>,<span class="dv">50</span>)</span></code></pre></div>
<div class="inline-figure"><img src="_main_files/figure-html/unnamed-chunk-57-5.png" width="672"></div>
<p>What about when <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are not equal?</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="hierarchical-generalization.html#cb62-1" aria-hidden="true" tabindex="-1"></a>plot_beta(<span class="dv">4</span>,<span class="dv">2</span>)</span></code></pre></div>
<div class="inline-figure">
<img src="_main_files/figure-html/unnamed-chunk-58-7.png" width="672">
This allows us to capture skewed priors, perhaps capturing a belief that the coin has a specific bias.</div>
<p>Now, what if <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are less than 1?</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="hierarchical-generalization.html#cb63-1" aria-hidden="true" tabindex="-1"></a>plot_beta(<span class="fl">0.5</span>,<span class="fl">0.5</span>)</span></code></pre></div>
<div class="inline-figure">
<img src="_main_files/figure-html/unnamed-chunk-59-9.png" width="672">
This might capture the belief that the coin is strongly biased, but we aren‚Äôt sure in which direction.</div>
<div id="conjugate-distributions" class="section level3" number="6.1.1">
<h3>
<span class="header-section-number">6.1.1</span> Conjugate distributions<a class="anchor" aria-label="anchor" href="#conjugate-distributions"><i class="fas fa-link"></i></a>
</h3>
<p>The Beta distribution is the <em>conjugate distribution</em> for the Binomial distribution. This means that when the likelihood is a Binomial distribution and the prior is a Beta distribution, then the posterior is also a Beta distribution. Specifically, after making these assumptions,</p>
<p><span class="math display">\[
P(\theta|D) = \text{Beta}(\theta; \alpha + k, \beta + n-k)
\]</span></p>
<p>The parameters of the posterior distribution are (1) the sum of <span class="math inline">\(\alpha\)</span> from the prior and the number of observed heads and (2) the sum of <span class="math inline">\(\beta\)</span> from the prior and the number of observed tails. This means that the parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> of the Beta prior have a natural interpretation as ‚Äúvirtual‚Äô‚Äô flips.‚Äù For example, the larger <span class="math inline">\(\alpha\)</span> is compared to <span class="math inline">\(\beta\)</span>, the more biased toward heads we expect <span class="math inline">\(\theta\)</span> to be. Additionally, the larger <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are, the more certain (less diffuse) the prior is.</p>
</div>
<div id="parameter-estimation" class="section level3" number="6.1.2">
<h3>
<span class="header-section-number">6.1.2</span> Parameter estimation<a class="anchor" aria-label="anchor" href="#parameter-estimation"><i class="fas fa-link"></i></a>
</h3>
<p>Because we used a conjugate distribution, we can use our same <code>plot_beta</code> function to generate posterior probability distributions after some coin flips.</p>
<p>Suppose we start with a fairly strong belief that a coin is fair, represented by this distribution:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="hierarchical-generalization.html#cb64-1" aria-hidden="true" tabindex="-1"></a>plot_beta(<span class="dv">30</span>,<span class="dv">30</span>)</span></code></pre></div>
<div class="inline-figure">
<img src="_main_files/figure-html/unnamed-chunk-60-11.png" width="672">
Now, suppose you flip a coin 20 times and it comes up heads every time. What should you think about the bias of the coin now? According to our model:</div>
<div class="sourceCode" id="cb65"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="hierarchical-generalization.html#cb65-1" aria-hidden="true" tabindex="-1"></a>plot_beta(<span class="dv">30</span><span class="op">+</span><span class="dv">20</span>,<span class="dv">30</span>)</span></code></pre></div>
<div class="inline-figure">
<img src="_main_files/figure-html/unnamed-chunk-61-13.png" width="672">
As you can see, this should cause you to shift your beliefs somewhat.</div>
<p>This wasn‚Äôt totally realistic, though. If you picked a coin off the ground, your prior beliefs about it being bias would probably look more like this:</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="hierarchical-generalization.html#cb66-1" aria-hidden="true" tabindex="-1"></a>plot_beta(<span class="dv">2000</span>,<span class="dv">2000</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-62-15.png" width="672">
What happens if we <em>now</em> flipped this coin 20 times and it came up heads every time?</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="hierarchical-generalization.html#cb67-1" aria-hidden="true" tabindex="-1"></a>plot_beta(<span class="dv">2000</span><span class="op">+</span><span class="dv">20</span>,<span class="dv">2000</span>)</span></code></pre></div>
<div class="inline-figure">
<img src="_main_files/figure-html/unnamed-chunk-63-17.png" width="672">
You might be mildly surprised, but those 20 flips wouldn‚Äôt be enough to budge your estimate about the bias of the coin by much.</div>
</div>
</div>
<div id="overhypotheses" class="section level2" number="6.2">
<h2>
<span class="header-section-number">6.2</span> Overhypotheses<a class="anchor" aria-label="anchor" href="#overhypotheses"><i class="fas fa-link"></i></a>
</h2>
<p>Flip 19 coins in a row and they all come up heads. What is the probability that the 20th coin comes up heads. Is it higher than 0.5. Why?</p>
<div id="the-shape-bias" class="section level3" number="6.2.1">
<h3>
<span class="header-section-number">6.2.1</span> The shape bias<a class="anchor" aria-label="anchor" href="#the-shape-bias"><i class="fas fa-link"></i></a>
</h3>
</div>
</div>
<div id="kemp-et-al-introduction-and-results" class="section level2" number="6.3">
<h2>
<span class="header-section-number">6.3</span> Kemp et al introduction and results<a class="anchor" aria-label="anchor" href="#kemp-et-al-introduction-and-results"><i class="fas fa-link"></i></a>
</h2>

</div>
</div>








  <div class="chapter-nav">
<div class="prev"><a href="categorization.html"><span class="header-section-number">5</span> Categorization</a></div>
<div class="empty"></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#hierarchical-generalization"><span class="header-section-number">6</span> Hierarchical generalization</a></li>
<li>
<a class="nav-link" href="#the-beta-binomial-model"><span class="header-section-number">6.1</span> The Beta-Binomial model ü™ô</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#conjugate-distributions"><span class="header-section-number">6.1.1</span> Conjugate distributions</a></li>
<li><a class="nav-link" href="#parameter-estimation"><span class="header-section-number">6.1.2</span> Parameter estimation</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#overhypotheses"><span class="header-section-number">6.2</span> Overhypotheses</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#the-shape-bias"><span class="header-section-number">6.2.1</span> The shape bias</a></li></ul>
</li>
<li><a class="nav-link" href="#kemp-et-al-introduction-and-results"><span class="header-section-number">6.3</span> Kemp et al introduction and results</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Computational Psychology in Python</strong>" was written by Alan Jern. It was last built on 2022-03-20.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
