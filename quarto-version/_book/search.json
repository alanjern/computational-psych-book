[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Computational Psychology",
    "section": "",
    "text": "Welcome"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1¬† Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. ‚ÄúLiterate Programming.‚Äù Comput. J. 27 (2): 97‚Äì111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2¬† Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. ‚ÄúLiterate Programming.‚Äù Comput.\nJ. 27 (2): 97‚Äì111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "index.html#thanks",
    "href": "index.html#thanks",
    "title": "Introduction to Computational Psychology",
    "section": "Thanks",
    "text": "Thanks\nThis book borrows inspiration and content (especially Chapters 2 and 7) from Fausto Carcassi‚Äôs Introduction to Cognitive Modelling in R book and I am tremendously grateful to him for sharing his book publicly. Hopefully this resource will be equally helpful to others.\nA number of the modeling examples and homework assignments are adapted from code written by Danielle Navarro from previous iterations of her Computational Cognitive Science course with Andy Perfors. I am very grateful to both of them for making all of their materials public (and well documented).\nYour feedback is welcome and encouraged."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Introduction to Computational Psychology",
    "section": "License",
    "text": "License\n\n\n\n\n\nAnyone is free to reuse and adapt this book for their own non-commercial purposes, with attribution. If you do use this book in any way, please tell me about it."
  },
  {
    "objectID": "01-intro.html#representations",
    "href": "01-intro.html#representations",
    "title": "1¬† Why computational modeling?",
    "section": "1.1 Representations üî∏",
    "text": "1.1 Representations üî∏\nWe don‚Äôt perceive the world as it truly is. As one example, the visible spectrum that our eyes can detect is just a fraction of the full electromagnetic spectrum. Similarly, we can only hear a narrow range of audible sound frequencies. In other words, we perceive an incomplete picture of the surrounding world.\n\n\n\nSource: Abstruse Goose.\n\n\nSimilarly, we are constantly making assumptions about the things we see and hear and using those assumptions to fill in gaps.\nWhat we have in our heads is a kind of model of the world around us ‚Äì what cognitive scientists call a mental representation. These representations help us to reach rapid conclusions about things involving language, causes and effects, concepts, mental states, and many other aspects of cognition.\nSome of the key questions for cognitive scientists who use computational models are:\n\nWhat mental representations do we rely on?\nHow do our minds use these representations to learn when we get new information?\nWhat kind of information do we get and how do our expectations about the kind of information we‚Äôre getting to affect how we use it?\n\nThis book will elaborate, with examples, on each of these questions."
  },
  {
    "objectID": "01-intro.html#homework-1-build-your-first-computational-model",
    "href": "01-intro.html#homework-1-build-your-first-computational-model",
    "title": "1¬† Why computational modeling?",
    "section": "1.2 Homework 1: Build your first computational model üíª",
    "text": "1.2 Homework 1: Build your first computational model üíª\n\n\n\n\n\nTo get some initial experience with computational modeling, you‚Äôll build and experiment with a simple model of classical conditioning developed by Robert Rescorla and Allan Wagner ‚Äì now called the Rescorla-Wagner model.\nAll homework assignments for this book will be done in Google Colab. Click the button above at the top of this section view Homework 1.\nIf you‚Äôre unfamiliar with Colab (or Jupyter Notebooks), watch this brief introduction video.\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou‚Äôll have to make a copy of the notebook saved to your own Drive in order to edit it."
  },
  {
    "objectID": "02-bayes.html#basic-probability",
    "href": "02-bayes.html#basic-probability",
    "title": "2¬† Bayesian inference",
    "section": "2.1 Basic probability üé≤",
    "text": "2.1 Basic probability üé≤\n\nConditional probability: \\(P(b|a) = \\frac{P(a,b)}{P(a)}\\)\nChain rule: \\(P(a,b) = P(b|a)P(a)\\)\nMarginalization: \\(P(d) = \\sum_h P(d,h) = \\sum_h P(d|h) P(h)\\)\nBayes‚Äôs rule: \\(P(h|d) = \\frac{P(d|h) P(h)}{P(d)} = \\frac{P(d|h) P(h)}{\\sum_h P(d|h) P(h)}\\). \\(P(d|h)\\) is referred to as the likelihood, \\(P(h)\\) is the prior, and \\(P(h|d)\\) is the posterior."
  },
  {
    "objectID": "02-bayes.html#a-motivating-example-sampling-from-a-bag",
    "href": "02-bayes.html#a-motivating-example-sampling-from-a-bag",
    "title": "2¬† Bayesian inference",
    "section": "2.2 A motivating example: Sampling from a bag üëù",
    "text": "2.2 A motivating example: Sampling from a bag üëù\nSuppose you have a bag full of black and red balls. You can‚Äôt see inside the bag and you don‚Äôt know how many black and red balls are inside, but you know that there are nine total balls in the bag.\nYou want to know how many black balls and red balls there are. There are a finite number of hypotheses: {0 black balls, 1 black ball, 2 black balls, ‚Ä¶, 9 black balls}. Let‚Äôs call these hypotheses \\(B_0\\), \\(B_1\\), etc., respectively.\nYou don‚Äôt know which hypothesis is true, but you might have some idea which hypotheses are more likely than others. Therefore, it is natural to represent your uncertainty with a probability distribution over the possible unknown states that the world could be in ‚Äì in this case, the 10 hypotheses. Each hypothesis gets assigned a probability, and the probabilities sum to 1.\nFor simplicity, let‚Äôs assume that you don‚Äôt have any idea which hypotheses are more likely. In other words, you give every hypothesis the same probability: 1/10 = 0.1. This is also called a uniform distribution over hypotheses. This distribution is your prior.\nNow suppose you put your hand in the bag and pull out a ball at random. The possible observations are: {black, red}, Let‚Äôs call them \\(B\\) and \\(R\\), respectively. The probability of observing each color depends on which hypothesis is true, i.e., how many balls of each color are in the bag. For instance, if \\(B_0\\) is true (there are 0 black balls in the bag), then the probability of observing a red ball is 1 (\\(P(R|B_0)=1\\)), and the probability of observing a black ball is 0 (\\(P(B|B_0)=0\\)). These expressions that tell us how probable our observations are, given a specific hypothesis, are your likelihoods.\n\n2.2.1 Sampling from the generative model\nNow we have a distribution over hypotheses (a prior), \\(P(h)\\), and a distribution over observations given each hypothesis (a likelihood), \\(P(d|h)\\). These two things allow us to create a generative model, a model for sampling new data.\nHow do we sample from the generative model? Note that which hypothesis \\(h\\) is true does not depend on the data, while the data \\(d\\) depends on which hypothesis is true. Therefore, we can sample from the generative model using the following two-step process:\n\nSample a hypothesis from the prior.\nSample data given the hypothesis, using the likelihood.\n\nLet‚Äôs first create a vector with the probability of each hypothesis:\n\nimport numpy as np\nimport random\n\nrandom.seed(2022) # set random seed to get same results every time\n\nh_priors = np.repeat(0.1,10)\nprint(h_priors)\n\n[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n\n\nNow we‚Äôll do the first step: create a vector of 10000 hypotheses sampled from the prior:\n\nprior_samples = np.array(random.choices(np.arange(0,10,1),\n                   weights = h_priors, \n                   k = 10000))\n                   \nprint(prior_samples[0:9]) # printing out just a few\n\n[5 4 3 0 7 9 4 6 8]\n\n\nHere, each number corresponds to one hypothesis: 0 corresponds to \\(B_0\\), 1 to \\(B_1\\), and so on. Each sample represents one possible way (a hypothesis) the world could be. Since the prior was uniform (each hypothesis had the same probability), each hypothesis appears about equally often. We can plot all the samples to verify:\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nn, bins, patches = ax.hist(prior_samples, bins=10)\nax.set_xlabel('Prior sample')\nax.set_ylabel('Number of samples')\n\nText(0, 0.5, 'Number of samples')\n\n\n\n\n\nNow for the next step. For each sample in prior_samples, we want to sample an observation. To do that, let‚Äôs pause for a second and think about the probability of pulling a black ball given that hypothesis \\(B_3\\) is true, for example. This means that there are 3 black balls and 6 red balls in the bag. So the probability of pulling a black ball from the bag at random will be 3/9.\nGeneralizing this idea, we can get the probability of pulling a black ball from the bag by dividing the elements of prior_samples by 9:\n\np_black = prior_samples / 9\nprint(p_black[0:4]) # print out just a few\n\n[0.55555556 0.44444444 0.33333333 0.        ]\n\n\nNow, to complete our generative model, we just need to sample one value for each element of p_black. Each sample represents a draw from a bag.\n\nball_samples = np.random.binomial(n = np.repeat(1,len(p_black)),\n                                  p = p_black)\nprint(ball_samples[0:9])\n\n[0 0 0 0 1 1 1 0 1]\n\n\nball_samples is 1 for black and 0 for red. Once again, let‚Äôs plot all our samples.\n\nfig, ax = plt.subplots()\nn, bins, patches = ax.hist(ball_samples, bins=2)\nax.set_xticks([0,1])\nax.set_ylabel('Number of samples')\n\nText(0, 0.5, 'Number of samples')\n\n\n\n\n\nYou can think of this plot representing our overall beliefs about the number of red and black balls in the bag, averaged over all possible hypotheses.\nNot surprisingly, we got about equal numbers of red and black balls. This makes sense: We didn‚Äôt have any prior expectations about whether red or black balls were more likely in the bag.\nHow should our beliefs change after we pull a ball out of the bag? That is, how should we respond to evidence?"
  },
  {
    "objectID": "02-bayes.html#bayesian-updating-learning-from-evidence",
    "href": "02-bayes.html#bayesian-updating-learning-from-evidence",
    "title": "2¬† Bayesian inference",
    "section": "2.3 Bayesian updating: Learning from evidence ü§î",
    "text": "2.3 Bayesian updating: Learning from evidence ü§î\nLet‚Äôs apply Bayes‚Äôs rule to see how to optimally incorporate new data into your beliefs.\n\n2.3.1 Applying Bayes‚Äôs rule to the bag case\nSuppose you have a uniform prior distribution over the 10 hypotheses about balls in the bag. Now you pick a ball and it‚Äôs black. Given this observation \\(B\\), how should you change the probabilities you give to each hypothesis?\nIntuitively, you should now give a little bit more probability to those hypotheses that have more black balls than red balls, because those are the hypotheses that make your observations more likely. Moreover, you can safely exclude hypothesis \\(B_0\\), because your observation would be impossible if \\(B_0\\) were true. Let‚Äôs calculate this with Bayes‚Äôs rule.\nThe prior is the vector h_priors defined above. Given that we have observed \\(B\\), the likelihood should tell us, for each hypothesis, the probability of \\(B\\) given that hypothesis. For example, for \\(B_9\\), the likelihood \\(P(B|B_9) = 1\\). For \\(B_8\\), \\(P(B|B_8) = 8/9\\), because 8 of the 9 balls are black.\nGeneralizing this idea, \\(P(B|B_n) = n/9\\). We can therefore compute the likelihoods for all hypotheses in a vector:\n\nlikelihoods = np.arange(0,10,1) / 9\n\nprint(likelihoods)\n\n[0.         0.11111111 0.22222222 0.33333333 0.44444444 0.55555556\n 0.66666667 0.77777778 0.88888889 1.        ]\n\n\nNow suppose we want to find the probability of hypothesis \\(B_5\\) after observing one draw \\(B\\). Let‚Äôs apply Bayes‚Äôs rule:\n\\[P(B_5 | B) = \\frac{P(B|B_5) P(B_5)}{\\sum_h{p(B|h) P(h)}}\\]\nLet‚Äôs compute the parts we need to calculate \\(P(B_5 | B)\\).\n\n# Prior\np_B5 = h_priors[3]\n\n# Likelihood\nlikelihood_B5 = likelihoods[5]\n\n# Data\np_B = sum(likelihoods*h_priors)\n\n# Posterior\np_B5_given_B = p_B5 * likelihood_B5 / p_B\n\n# Print out results\nprint(\"P(B5) = \" + str(p_B5)) # Prior\nprint(\"P(B|B5) = \" + str(likelihood_B5)) # Likelihood\nprint(\"P(B) = \" + str(p_B)) # Data\nprint(\"P(B5|B) = \" + str(p_B5_given_B)) # Posterior\n\nP(B5) = 0.1\nP(B|B5) = 0.5555555555555556\nP(B) = 0.5\nP(B5|B) = 0.11111111111111112\n\n\nLet‚Äôs update the probabilities for all hypotheses in a more compact way.\n\nposteriors = (likelihoods * h_priors) / sum(likelihoods * h_priors)\n\nfor i in range(len(posteriors)):\n  print(\"P(B\" + str(i) + \"|B) = \" + str(posteriors[i]))\n\nP(B0|B) = 0.0\nP(B1|B) = 0.022222222222222223\nP(B2|B) = 0.044444444444444446\nP(B3|B) = 0.06666666666666667\nP(B4|B) = 0.08888888888888889\nP(B5|B) = 0.11111111111111112\nP(B6|B) = 0.13333333333333333\nP(B7|B) = 0.15555555555555556\nP(B8|B) = 0.17777777777777778\nP(B9|B) = 0.2\n\n\nAs expected, Bayes‚Äôs rule says we should increase the probability we assign to hypotheses with more black balls than red balls. Additionally, let‚Äôs double-check that the posterior probabilities sum to 1 (a requirement for a valid probability distribution).\n\nsum(posteriors)\n\n1.0\n\n\nFinally, let‚Äôs plot the posterior probabilities.\n\nfig, ax = plt.subplots()\nhypotheses = ('B0', 'B1', 'B2', 'B3', 'B4',\n              'B5', 'B6', 'B7', 'B8', 'B9')\ny_pos = np.arange(len(hypotheses))\n\nax.barh(y_pos, posteriors, align='center')\nax.set_yticks(y_pos)\nax.set_yticklabels(hypotheses)\nax.set_xlabel('Probability')\nax.set_ylabel('Hypothesis')\n\nText(0, 0.5, 'Hypothesis')\n\n\n\n\n\n\n\n2.3.2 How to avoid calculating P(d)\nIn practice, we generally do not need to calculate the \\(P(d)\\) (the denominator in Bayes‚Äôs rule) explicitly. I‚Äôll give you the general idea why in this section.\nFirst, we create a vector of prior probabilities, which has as many components as there are hypotheses. We‚Äôll just reuse h_priors. Note that the probabilities sum to 1, as they should because it‚Äôs a probability distribution.\n\nh_priors\n\narray([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\n\n\nNext, we create a likelihood array. When we did calculations above, we only had a vector with the likelihoods for a specific observation. However, we would like to have something that encodes the likelihood function for each possible observation given each possible hypothesis, rather than just for a specific observation.\nIn this example, there are two possible observations: \\(B\\) and \\(R\\). We can encode the likelihood as an \\(m \\times n\\) array where \\(m\\) is the number of hypotheses and \\(n\\) is the number of possible observations. In our case: \\(10 \\times 2\\).\n\nlikelihood_array = np.array((np.arange(0,10,1) / 9,\n                             1-(np.arange(0,10,1) / 9))).T\nprint(likelihood_array)\n\n[[0.         1.        ]\n [0.11111111 0.88888889]\n [0.22222222 0.77777778]\n [0.33333333 0.66666667]\n [0.44444444 0.55555556]\n [0.55555556 0.44444444]\n [0.66666667 0.33333333]\n [0.77777778 0.22222222]\n [0.88888889 0.11111111]\n [1.         0.        ]]\n\n\nNow we multiply the prior and likelihoods together (the numerator of Bayes‚Äôs rule) element-wise (first element gets multiplied with first element, second element by second element, etc.):\n\nprior_array = np.array((h_priors, h_priors)).T\nbayes_numerator = likelihood_array * prior_array\n\nprint(bayes_numerator)\n\n[[0.         0.1       ]\n [0.01111111 0.08888889]\n [0.02222222 0.07777778]\n [0.03333333 0.06666667]\n [0.04444444 0.05555556]\n [0.05555556 0.04444444]\n [0.06666667 0.03333333]\n [0.07777778 0.02222222]\n [0.08888889 0.01111111]\n [0.1        0.        ]]\n\n\nFinally, we want a distribution for each column, i.e., a distribution over hypotheses given each observation. Therefore, we sum each column and then divide each element by the sum of its column:\n\nposteriors = bayes_numerator / np.sum(bayes_numerator, axis = 0)\nprint(posteriors)\n\n[[0.         0.2       ]\n [0.02222222 0.17777778]\n [0.04444444 0.15555556]\n [0.06666667 0.13333333]\n [0.08888889 0.11111111]\n [0.11111111 0.08888889]\n [0.13333333 0.06666667]\n [0.15555556 0.04444444]\n [0.17777778 0.02222222]\n [0.2        0.        ]]\n\n\nAnd that gives us the posterior without us having to explicitly calculate the evidence for each observation!\n\n\n\n\n\n\nNote\n\n\n\nThe general idea is this. Because the denominator of Bayes‚Äôs rule, for a fixed observation, is a constant, you can usually get away with computing \\(P(d|h) P(h)\\) for every possible hypothesis \\(h\\) and then ‚Äúnormalize‚Äù the resulting values so that they sum to 1 (remember that they have to in order for it to be a valid probability distribution)."
  },
  {
    "objectID": "02-bayes.html#bayes-exercises",
    "href": "02-bayes.html#bayes-exercises",
    "title": "2¬† Bayesian inference",
    "section": "2.4 Exercises üìù",
    "text": "2.4 Exercises üìù\n\n2.4.1 Taxi cabs\n80% of the taxi cabs in Simpletown are green and 20% are yellow. An hit-and-run accident happened at night involving a taxi. A witness claimed that the taxi was yellow. After extensive testing, it is determined that the witness can correctly identify the color of a taxi only 75% of the time under conditions like the ones present during the accident. What is the probability that the taxi was yellow?\n\n\n2.4.2 Flipping coins\nYou observe a sequence of coin flips and want to determine if the coin is a trick coin (always comes up heads) or a normal coin. Let \\(P(\\text{heads}) = \\theta\\). Let \\(h_1\\) be the hypothesis that \\(\\theta = 0.5\\) (fair coin). Let \\(h_2\\) be the hypothesis that \\(\\theta = 1\\) (trick coin).\nFor this problem, we will define something called prior odds, which is the ratio of prior probabilities assigned to two hypotheses: \\(\\frac{P(h_1)}{P(h_2)}\\). Because most coins aren‚Äôt trick coins, we assume that \\(\\frac{P(h_1)}{P(h_2)} = 999\\), indicating a very strong (999 to 1) prior probability in favor of fair coins. We can now compute the posterior odds, the ratio of posterior probabilities for the two hypotheses after observing some data \\(d\\): \\(\\frac{P(h_1|d)}{P(h_2|d)}\\).\nCompute the posterior odds after observing the following sequences of coin flips:\n\nHHTHT\nHHHHH\nHHHHHHHHHH"
  },
  {
    "objectID": "02-bayes.html#solutions",
    "href": "02-bayes.html#solutions",
    "title": "2¬† Bayesian inference",
    "section": "2.5 Solutions",
    "text": "2.5 Solutions\n\n2.5.1 Taxi cabs\nLet \\(h_1\\) be the hypothesis that the taxi is yellow. Let \\(h_2\\) be the hypothesis that the taxi is green. Let data \\(d\\) be the witness report that the taxi was yellow. Given the problem statement, \\(P(h_1) = 0.2\\) and \\(P(h_2) = 0.8\\). The witness is only accurate 75% of the time, so \\(P(d|h1) = 0.75\\) (the witness saw a yellow taxi and correctly identified it) and \\(P(d|h2) = 0.25\\) (the witness saw a green taxi but identified it as yellow). Now we apply Bayes‚Äôs rule:\n\\[\\begin{align}\nP(h_1|d) &= \\frac{P(d|h_1) P(h_1)}{P(d)} \\\\\n&= \\frac{P(d|h_1) P(h_1)}{P(d|h_1) P(h_1) + P(d|h_2) P(h_2)} \\\\\n&= \\frac{(0.75) (0.2)}{(0.75)(0.2) + (0.25)(0.8)} \\approx 0.43\n\\end{align}\\]\nBecause yellow cabs are rare (have low prior probability), it is actually more probable that the cab was green, even though the witness is 75% accurate.\n\n\n2.5.2 Flipping coins\n\nHHTHT\n\\[\n\\begin{align}\n\\frac{P(h_1|d)}{P(h_2|d)} &= \\frac{P(d|h_1)}{P(d|h_2)} \\frac{P(h_1)}{P(h_2)} \\\\\n&= \\frac{(1/2)^5}{0} \\times 999 = \\inf\n\\end{align}\n\\] This sequence isn‚Äôt even possible under \\(h_2\\) so we have infinite evidence in favor of \\(h_1\\).\n\n\nHHHHH\n\\[\n\\begin{align}\n\\frac{P(h_1|d)}{P(h_2|d)} &= \\frac{P(d|h_1)}{P(d|h_2)} \\frac{P(h_1)}{P(h_2)} \\\\\n&= \\frac{(1/2)^5}{1^5} \\times 999 = 31.2\n\\end{align}\n\\]\nThis sequence favors \\(h_1\\) by a factor of about 31. Even five heads in a row can‚Äôt overcome our strong prior favoring \\(h_1\\).\n\n\nHHHHHHHHHH\n\\[\n\\begin{align}\n\\frac{P(h_1|d)}{P(h_2|d)} &= \\frac{P(d|h_1)}{P(d|h_2)} \\frac{P(h_1)}{P(h_2)} \\\\\n&= \\frac{(1/2)^{10}}{1^{10}} \\times 999 = 0.98\n\\end{align}\n\\]\nNow the evidence favors \\(h_2\\) (trick coin) just barely."
  }
]