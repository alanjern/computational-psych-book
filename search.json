[{"path":"index.html","id":"preface","chapter":"1 Preface","heading":"1 Preface","text":"first version digital book Computational Psychology course ‚Äì cognitive modeling course. includes homework assignments written Python.","code":""},{"path":"index.html","id":"thanks","chapter":"1 Preface","heading":"1.1 Thanks","text":"book borrows inspiration content Fausto Carcassi‚Äôs Introduction Cognitive Modelling R book tremendously grateful sharing book publicly. Hopefully resource equally helpful others.number modeling examples homework assignments adapted code written Danielle Navarro previous iterations Computational Cognitive Science course Andy Perfors. grateful making materials public (well documented).feedback welcome encouraged.","code":""},{"path":"index.html","id":"license","chapter":"1 Preface","heading":"1.2 License","text":"Anyone free reuse repurpose book non-commercial purposes, attribution.","code":""},{"path":"intro.html","id":"intro","chapter":"2 Why computational modeling?","heading":"2 Why computational modeling?","text":"field psychology full theories. book focused specific type theory: type can formalized computational model.advantage computational (mathematical) theory one can‚Äôt expressed computational terms? biggest advantage precision. example, suppose say attention like spotlight üî¶: can attend things currently within light, can control light shining, things outside light outside awareness. kind theory ‚Äì analogy-based one ‚Äì ‚Äôs good start making general qualitative predictions attention works.‚Äôll quickly run problems want make precise quantitative predictions attention. big spotlight? size expand contract? quickly move around? attention completely absent outside spotlight ramp get near edge light? words, wanted build computer model theory, simple analogy doesn‚Äôt cut .Computational models, nothing else, force us explicit assumptions.","code":""},{"path":"intro.html","id":"representations","chapter":"2 Why computational modeling?","heading":"2.1 Representations üî∏","text":"don‚Äôt perceive world truly . give one example, visible spectrum eyes can detect just fraction full electromagnetic spectrum. words, ‚Äôre seeing incomplete picture surrounding world.\nFigure 2.1: visible light spectrum. Source: Philip Ronan/Wikipedia.\nSimilarly, constantly making assumptions things see hear using assumptions fill gaps.heads kind model world around us ‚Äì cognitive scientists call mental representation. representations help us reach rapid conclusions things involving language, causes effects, concepts, mental states, many aspects cognition.key questions cognitive scientists use computational models :mental representations rely ?minds use representations learn get new information?kind information get expectations kind information ‚Äôre getting affect use ?book elaborate, examples, questions.","code":""},{"path":"intro.html","id":"homework-1-build-your-first-computational-model","chapter":"2 Why computational modeling?","heading":"2.2 Homework 1: Build your first computational model üíª","text":"get initial experience computational modeling, ‚Äôll build experiment simple model classical conditioning developed Robert Rescorla Allan Wagner ‚Äì now called Rescorla-Wagner model.homework assignments book done Google Colab. Click button top section view Homework 1.‚Äôre unfamiliar Colab (Jupyter Notebooks), watch brief introduction video.Note: ‚Äôll make copy notebook saved Drive order edit .","code":""},{"path":"bayes.html","id":"bayes","chapter":"3 Bayesian inference","heading":"3 Bayesian inference","text":"chapter reviews basic probability Bayesian inference. might asking : psychology? answer becomes clear recognize ‚Äôre making sense world drawing inferences. see ambiguous image, rabbit duck? someone mumbles something, say ‚Äúhello‚Äù ‚Äúgo hell?‚Äù take pill headache goes away, pill eliminate headache headache go away ?\nFigure 3.1: duck-rabbit illusion.\nexamples, one hypothesis observed. Probability Bayesian inference provide tools optimally determining probable different hypotheses . One claims book people making inferences situations like , inferences often well predicted optimal inferences dictated probability theory.","code":""},{"path":"bayes.html","id":"basic-probability","chapter":"3 Bayesian inference","heading":"3.1 Basic probability üé≤","text":"Conditional probability: \\(P(b|) = \\frac{P(,b)}{P()}\\)Chain rule: \\(P(,b) = P(b|)P()\\)Marginalization: \\(P(d) = \\sum_h P(d,h) = \\sum_h P(d|h) P(h)\\)Bayes‚Äôs rule: \\(P(h|d) = \\frac{P(d|h) P(h)}{P(d)} = \\frac{P(d|h) P(h)}{\\sum_h P(d|h) P(h)}\\). \\(P(d|h)\\) referred likelihood, \\(P(h)\\) prior, \\(P(h|d)\\) posterior.","code":""},{"path":"bayes.html","id":"a-motivating-example-sampling-from-a-bag","chapter":"3 Bayesian inference","heading":"3.2 A motivating example: Sampling from a bag üëù","text":"Suppose bag full black red balls. can‚Äôt see inside bag don‚Äôt know many black red balls inside, know nine total balls bag.want know many black balls red balls . finite number hypotheses: {0 black balls, 1 black ball, 2 black balls, ‚Ä¶, 9 black balls}. Let‚Äôs call hypotheses \\(B_0\\), \\(B_1\\), etc., respectively.don‚Äôt know hypothesis true, might idea hypotheses likely others. Therefore, natural represent uncertainty probability distribution possible unknown states world ‚Äì case, 10 hypotheses. hypothesis gets assigned probability, probabilities sum 1.simplicity, let‚Äôs assume don‚Äôt idea hypotheses likely. words, give every hypothesis probability: 1/10 = 0.1. also called uniform distribution hypotheses. distribution prior.Now suppose put hand bag pull ball random. possible observations : {black, red}, Let‚Äôs call \\(B\\) \\(R\\), respectively. probability observing color depends hypothesis true, .e., many balls color bag. instance, \\(B_0\\) true (0 black balls bag), probability observing red ball 1 (\\(P(R|B_0)=1\\)), probability observing black ball 0 (\\(P(B|B_0)=0\\)). expressions tell us probable observations , given specific hypothesis, likelihoods.","code":""},{"path":"bayes.html","id":"sampling-from-the-generative-model","chapter":"3 Bayesian inference","heading":"3.2.1 Sampling from the generative model","text":"Now distribution hypotheses (prior), \\(P(h)\\), distribution observations given hypothesis (likelihood), \\(P(d|h)\\). two things allow us create generative model, model sampling new data.sample generative model? Note hypothesis \\(h\\) true depend data, data \\(d\\) depends hypothesis true. Therefore, can sample generative model using following two-step process:Sample hypothesis prior.Sample data given hypothesis, using likelihood.Let‚Äôs first create vector probability hypothesis:Now ‚Äôll first step: create vector 10000 hypotheses sampled prior:, number corresponds one hypothesis: 0 corresponds \\(B_0\\), 1 \\(B_1\\), . sample represents one possible way (hypothesis) world . Since prior uniform (hypothesis probability), hypothesis appears equally often. can plot samples verify:Now next step. sample prior_samples, want sample observation. , let‚Äôs pause second think probability pulling black ball given hypothesis \\(B_3\\) true, example. means 3 black balls 6 red balls bag. probability pulling black ball bag random 3/9.Generalizing idea, can get probability pulling black ball bag dividing elements prior_samples 9:Now, complete generative model, just need sample one value element p_black. sample represents draw bag.ball_samples 1 black 0 red. , let‚Äôs plot samples.can think plot representing overall beliefs number red black balls bag, averaged possible hypotheses.surprisingly, got equal numbers red black balls. makes sense: didn‚Äôt prior expectations whether red black balls likely bag.beliefs change pull ball bag? , respond evidence?","code":"import numpy as np\nimport random\n\nrandom.seed(2022) # set random seed to get same results every time\n\nh_priors = np.repeat(0.1,10)\nprint(h_priors)## [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]prior_samples = np.array(random.choices(np.arange(0,10,1),\n                   weights = h_priors, \n                   k = 10000))\n                   \nprint(prior_samples[0:9]) # printing out just a few## [5 4 3 0 7 9 4 6 8]import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nn, bins, patches = ax.hist(prior_samples, bins=10)\nax.set_xlabel('Prior sample')\nax.set_ylabel('Number of samples')p_black = prior_samples / 9\nprint(p_black[0:4]) # print out just a few## [0.55555556 0.44444444 0.33333333 0.        ]ball_samples = np.random.binomial(n = np.repeat(1,len(p_black)),\n                                  p = p_black)\nprint(ball_samples[0:9])## [0 0 0 0 1 1 1 0 1]fig, ax = plt.subplots()\nn, bins, patches = ax.hist(ball_samples, bins=2)\nax.set_xticks([0,1])\nax.set_ylabel('Number of samples')"},{"path":"bayes.html","id":"bayesian-updating-learning-from-evidence","chapter":"3 Bayesian inference","heading":"3.3 Bayesian updating: Learning from evidence ü§î","text":"Let‚Äôs apply Bayes‚Äôs rule see optimally incorporate new data beliefs.","code":""},{"path":"bayes.html","id":"applying-bayess-rule-to-the-bag-case","chapter":"3 Bayesian inference","heading":"3.3.1 Applying Bayes‚Äôs rule to the bag case","text":"Suppose uniform prior distribution 10 hypotheses balls bag. Now pick ball ‚Äôs black. Given observation \\(B\\), change probabilities give hypothesis?Intuitively, now give little bit probability hypotheses black balls red balls, hypotheses make observations likely. Moreover, can safely exclude hypothesis \\(B_0\\), observation impossible \\(B_0\\) true. Let‚Äôs calculate Bayes‚Äôs rule.prior vector h_priors defined . Given observed \\(B\\), likelihood tell us, hypothesis, probability \\(B\\) given hypothesis. example, \\(B_9\\), likelihood \\(P(B|B_9) = 1\\). \\(B_8\\), \\(P(B|B_8) = 8/9\\), 8 9 balls black.Generalizing idea, \\(P(B|B_n) = n/9\\). can therefore compute likelihoods hypotheses vector:Now suppose want find probability hypothesis \\(B_5\\) observing one draw \\(B\\). Let‚Äôs apply Bayes‚Äôs rule:\\[P(B_5 | B) = \\frac{P(B|B_5) P(B_5)}{\\sum_h{p(B|h) P(h)}}\\]Let‚Äôs compute parts need calculate \\(P(B_5 | B)\\).Let‚Äôs update probabilities hypotheses compact way.expected, Bayes‚Äôs rule says increase probability assign hypotheses black balls red balls. Additionally, let‚Äôs double-check posterior probabilities sum 1 (requirement valid probability distribution).Finally, let‚Äôs plot posterior probabilities.","code":"likelihoods = np.arange(0,10,1) / 9\n\nprint(likelihoods)## [0.         0.11111111 0.22222222 0.33333333 0.44444444 0.55555556\n##  0.66666667 0.77777778 0.88888889 1.        ]# Prior\np_B5 = h_priors[3]\n\n# Likelihood\nlikelihood_B5 = likelihoods[5]\n\n# Data\np_B = sum(likelihoods*h_priors)\n\n# Posterior\np_B5_given_B = p_B5 * likelihood_B5 / p_B\n\n# Print out results\nprint(\"P(B5) = \" + str(p_B5)) # Prior## P(B5) = 0.1print(\"P(B|B5) = \" + str(likelihood_B5)) # Likelihood## P(B|B5) = 0.5555555555555556print(\"P(B) = \" + str(p_B)) # Data## P(B) = 0.5print(\"P(B5|B) = \" + str(p_B5_given_B)) # Posterior## P(B5|B) = 0.11111111111111112posteriors = (likelihoods * h_priors) / sum(likelihoods * h_priors)\n\nfor i in range(len(posteriors)):\n  print(\"P(B\" + str(i) + \"|B) = \" + str(posteriors[i]))## P(B0|B) = 0.0\n## P(B1|B) = 0.022222222222222223\n## P(B2|B) = 0.044444444444444446\n## P(B3|B) = 0.06666666666666667\n## P(B4|B) = 0.08888888888888889\n## P(B5|B) = 0.11111111111111112\n## P(B6|B) = 0.13333333333333333\n## P(B7|B) = 0.15555555555555556\n## P(B8|B) = 0.17777777777777778\n## P(B9|B) = 0.2sum(posteriors)## 1.0fig, ax = plt.subplots()\nhypotheses = ('B0', 'B1', 'B2', 'B3', 'B4',\n              'B5', 'B6', 'B7', 'B8', 'B9')\ny_pos = np.arange(len(hypotheses))\n\nax.barh(y_pos, posteriors, align='center')## <BarContainer object of 10 artists>ax.set_yticks(y_pos)\nax.set_yticklabels(hypotheses)\nax.set_xlabel('Probability')\nax.set_ylabel('Hypothesis')"},{"path":"bayes.html","id":"how-to-avoid-calculating-pd","chapter":"3 Bayesian inference","heading":"3.3.2 How to avoid calculating P(d)","text":"practice, generally need calculate \\(P(d)\\) (denominator Bayes‚Äôs rule) explicitly. ‚Äôll give general idea section.First, create vector prior probabilities, many components hypotheses. ‚Äôll just reuse h_priors. Note probabilities sum 1, ‚Äôs probability distribution.Next, create likelihood array. calculations , vector likelihoods specific observation. However, like something encodes likelihood function possible observation given possible hypothesis, rather just specific observation.example, two possible observations: \\(B\\) \\(R\\). can encode likelihood \\(m \\times n\\) array \\(m\\) number hypotheses \\(n\\) number possible observations. case: \\(10 \\times 2\\).Now multiply prior likelihoods together (numerator Bayes‚Äôs rule) element-wise (first element gets multiplied first element, second element second element, etc.):Finally, want distribution column, .e., distribution hypotheses given observation. Therefore, sum column divide element sum column:gives us posterior without us explicitly calculate evidence observation!general idea . denominator Bayes‚Äôs rule, fixed observation, constant, can usually get away computing \\(P(d|h) P(h)\\) every possible hypothesis \\(h\\) ‚Äúnormalize‚Äù resulting values sum 1 (remember order valid probability distribution).","code":"h_priors## array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])likelihood_array = np.array((np.arange(0,10,1) / 9,\n                             1-(np.arange(0,10,1) / 9))).T\nprint(likelihood_array)## [[0.         1.        ]\n##  [0.11111111 0.88888889]\n##  [0.22222222 0.77777778]\n##  [0.33333333 0.66666667]\n##  [0.44444444 0.55555556]\n##  [0.55555556 0.44444444]\n##  [0.66666667 0.33333333]\n##  [0.77777778 0.22222222]\n##  [0.88888889 0.11111111]\n##  [1.         0.        ]]prior_array = np.array((h_priors, h_priors)).T\nbayes_numerator = likelihood_array * prior_array\n\nprint(bayes_numerator)## [[0.         0.1       ]\n##  [0.01111111 0.08888889]\n##  [0.02222222 0.07777778]\n##  [0.03333333 0.06666667]\n##  [0.04444444 0.05555556]\n##  [0.05555556 0.04444444]\n##  [0.06666667 0.03333333]\n##  [0.07777778 0.02222222]\n##  [0.08888889 0.01111111]\n##  [0.1        0.        ]]posteriors = bayes_numerator / np.sum(bayes_numerator, axis = 0)\nprint(posteriors)## [[0.         0.2       ]\n##  [0.02222222 0.17777778]\n##  [0.04444444 0.15555556]\n##  [0.06666667 0.13333333]\n##  [0.08888889 0.11111111]\n##  [0.11111111 0.08888889]\n##  [0.13333333 0.06666667]\n##  [0.15555556 0.04444444]\n##  [0.17777778 0.02222222]\n##  [0.2        0.        ]]"},{"path":"bayes.html","id":"exercises","chapter":"3 Bayesian inference","heading":"3.4 Exercises üìù","text":"","code":""},{"path":"bayes.html","id":"taxi-cabs","chapter":"3 Bayesian inference","heading":"3.4.1 Taxi cabs","text":"80% taxi cabs Simpletown green 20% yellow. hit--run accident happened night involving taxi. witness claimed taxi yellow. extensive testing, determined witness can correctly identify color taxi 75% time conditions like ones present accident. probability taxi yellow?","code":""},{"path":"bayes.html","id":"flipping-coins","chapter":"3 Bayesian inference","heading":"3.4.2 Flipping coins","text":"observe sequence coin flips want determine coin trick coin (always comes heads) normal coin. Let \\(P(\\text{heads}) = \\theta\\). Let \\(h_1\\) hypothesis \\(\\theta = 0.5\\) (fair coin). Let \\(h_2\\) hypothesis \\(\\theta = 1\\) (trick coin).problem, define something called prior odds, ratio prior probabilities assigned two hypotheses: \\(\\frac{P(h_1)}{P(h_2)}\\). coins aren‚Äôt trick coins, assume \\(\\frac{P(h_1)}{P(h_2)} = 999\\), indicating strong (999 1) prior probability favor fair coins. can now compute posterior odds, ratio posterior probabilities two hypotheses observing data \\(d\\): \\(\\frac{P(h_1|d)}{P(h_2|d)}\\).Compute posterior odds observing following sequences coin flips:HHTHTHHHHHHHHHHHHHHH","code":""},{"path":"bayes.html","id":"solutions","chapter":"3 Bayesian inference","heading":"3.5 Solutions","text":"","code":""},{"path":"bayes.html","id":"taxi-cabs-1","chapter":"3 Bayesian inference","heading":"3.5.1 Taxi cabs","text":"Let \\(h_1\\) hypothesis taxi yellow. Let \\(h_2\\) hypothesis taxi green. Let data \\(d\\) witness report taxi yellow. Given problem statement, \\(P(h_1) = 0.2\\) \\(P(h_2) = 0.8\\). witness accurate 75% time, \\(P(d|h1) = 0.75\\) (witness saw yellow taxi correctly identified ) \\(P(d|h2) = 0.25\\) (witness saw green taxi identified yellow). Now apply Bayes‚Äôs rule:\\[\\begin{align}\nP(h_1|d) &= \\frac{P(d|h_1) P(h_1)}{P(d)} \\\\\n&= \\frac{P(d|h_1) P(h_1)}{P(d|h_1) P(h_1) + P(d|h_2) P(h_2)} \\\\\n&= \\frac{(0.75) (0.2)}{(0.75)(0.2) + (0.25)(0.8)} \\approx 0.43\n\\end{align}\\]yellow cabs rare (low prior probability), actually probable cab green, even though witness 75% accurate.","code":""},{"path":"bayes.html","id":"flipping-coins-1","chapter":"3 Bayesian inference","heading":"3.5.2 Flipping coins","text":"","code":""},{"path":"bayes.html","id":"hhtht","chapter":"3 Bayesian inference","heading":"HHTHT","text":"\\[\n\\begin{align}\n\\frac{P(h_1|d)}{P(h_2|d)} &= \\frac{P(d|h_1)}{P(d|h_2)} \\frac{P(h_1)}{P(h_2)} \\\\\n&= \\frac{(1/2)^5}{0} \\times 999 = \\inf\n\\end{align}\n\\]\nsequence isn‚Äôt even possible \\(h_2\\) infinite evidence favor \\(h_1\\).","code":""},{"path":"bayes.html","id":"hhhhh","chapter":"3 Bayesian inference","heading":"HHHHH","text":"\\[\n\\begin{align}\n\\frac{P(h_1|d)}{P(h_2|d)} &= \\frac{P(d|h_1)}{P(d|h_2)} \\frac{P(h_1)}{P(h_2)} \\\\\n&= \\frac{(1/2)^5}{1^5} \\times 999 = 31.2\n\\end{align}\n\\]sequence favors \\(h_1\\) factor 31. Even five heads row can‚Äôt overcome strong prior favoring \\(h_1\\).","code":""},{"path":"bayes.html","id":"hhhhhhhhhh","chapter":"3 Bayesian inference","heading":"HHHHHHHHHH","text":"\\[\n\\begin{align}\n\\frac{P(h_1|d)}{P(h_2|d)} &= \\frac{P(d|h_1)}{P(d|h_2)} \\frac{P(h_1)}{P(h_2)} \\\\\n&= \\frac{(1/2)^{10}}{1^{10}} \\times 999 = 0.98\n\\end{align}\n\\]Now evidence favors \\(h_2\\) (trick coin) just barely.","code":""},{"path":"generalization.html","id":"generalization","chapter":"4 Generalization","heading":"4 Generalization","text":"last chapter, learned much cognition making inferences. common inference ‚Äôre faced involves generalizing examples things new cases.child hears brand new word figure objects apply word .eat one candy assorted box try guess others might taste like.remember friend liked crosswords weekend trip cabin one time, guess might like book puzzles gift (generalizing interests).can apply Bayesian inference kinds problems?","code":""},{"path":"generalization.html","id":"healthy-hormone-levels","chapter":"4 Generalization","heading":"4.1 Healthy hormone levels üíâ","text":"example comes 2001 paper Josh Tenenbaum Thomas Griffiths1The basic problem: learn value healthy hormone level (say, 60) varies scale 1 100 (integers ). probability another value (say, 70) also healthy?","code":""},{"path":"generalization.html","id":"setting-up-a-model","chapter":"4 Generalization","heading":"4.1.1 Setting up a model","text":"","code":""},{"path":"generalization.html","id":"the-hypothesis-space","chapter":"4 Generalization","heading":"4.1.1.1 The hypothesis space","text":"start , ‚Äôll assume healthy values lie contiguous interval. Using term paper, interval consequential region \\(C\\).hypothesis space consists possible consequential regions. example, [0,100], [10,19], [44,45], valid hypotheses. full hypothesis space every valid interval 0 100.","code":""},{"path":"generalization.html","id":"prior","chapter":"4 Generalization","heading":"4.1.1.2 Prior","text":"much weight assign hypothesis? might reason favor shorter intervals longer ones, example. paper, use Erlang prior. Alternatively, simplicity calculation, assume uniform prior distribution, placing equal weight hypotheses, like previous chapter. tantamount making prior assumptions intervals probable.","code":""},{"path":"generalization.html","id":"likelihood","chapter":"4 Generalization","heading":"4.1.1.3 Likelihood","text":"Suppose learn healthy patient hormone level 60. likelihood observing value, assuming know hypothesis correct? , \\(P(x = 60 | h)\\). depends assume patient chosen.","code":""},{"path":"generalization.html","id":"sampling-assumptions","chapter":"4 Generalization","heading":"4.1.1.3.1 Weak vs.¬†strong sampling","text":"weak sampling, assume observation sampled full range possibilities, just coincidence happened get one consequential region (healthy patient). ‚Äôs true, probability getting particular value doesn‚Äôt depend hypothesis true:\\[\nP(x|h) = \\frac{1}{L}\n\\]\\(L\\) length range possible values (100 case).strong sampling, assume observation specifically chosen example consequential region \\(C\\). words, someone chose healthy person tested hormone levels example . case, probability seeing particular value depends size region:\\[\nP(x|h) = \\begin{cases} \n  \\frac{1}{|h|} & \\text{} x \\h \\\\\n  0 & \\text{otherwise}\n  \\end{cases}\n\\]\n\\(|h|\\) size \\(h\\), .e., number values contained \\(h\\). multiple observations \\(X = \\{x_1, x_2, \\ldots, x_n \\}\\), \\(P(X|h) = (1/|h|)^n\\). assume sample independent like coin flip.result strong sampling assumption size principle: among hypotheses include observed examples, smallest receive higher posterior probability higher likelihoods.\nFigure 4.1: Sample hypotheses. thickness lines indicates likelihood, depicting size principle. Image Griffiths & Tenenbaum (2001).\n","code":""},{"path":"generalization.html","id":"posterior","chapter":"4 Generalization","heading":"4.1.1.4 Posterior","text":"can now simply apply Bayes‚Äôs rule compute probability hypothesis, given observation (set observations).\\[\nP(h|X) = \\frac{P(X|h) P(h)}{\\sum_{h_i} P(X|h_i) P(h_i)}\n\\]","code":""},{"path":"generalization.html","id":"generalizing","chapter":"4 Generalization","heading":"4.1.2 Generalizing","text":"aren‚Äôt quite finished. Remember really want know probability new value \\(y\\) also healthy hormone level. point done assigned probability interval consequential region.want essentially two-step process:hypothesis \\(h\\), check see \\(y\\) ., check probable \\(h\\) consequential region \\(C\\), given observations \\(X\\).basic idea sometimes known hypothesis averaging don‚Äôt actually care hypothesis right one, ‚Äôll just average hypotheses, weighted probable . Specifically, ‚Äôll compute:\\[\nP(y \\C|X) = \\sum_h P(y \\C | h) P(h | X)\n\\]\nsecond term right computed earlier using Bayes‚Äôs rule.first term? time, ‚Äôll assume weak sampling ‚Äôs reason assume new value \\(y\\) chosen healthy value .","code":""},{"path":"generalization.html","id":"homework-2-finish-the-details","chapter":"4 Generalization","heading":"4.1.3 Homework 2: Finish the details","text":"haven‚Äôt provided details model assignment finish implementation , run simulations, collect small amount real data compare model .","code":""},{"path":"generalization.html","id":"the-number-game","chapter":"4 Generalization","heading":"4.2 The number game üî¢","text":"domains, requiring concepts restricted contiguous intervals realistic. Numbers one example. Consider space possible number concepts make integers 1 100. addition concepts like ‚Äúnumbers 20 50,‚Äù many plausible concepts like ‚Äúmultiples 10,‚Äù ‚Äúeven numbers,‚Äù ‚Äúpowers 3.‚ÄùConsider following problem: given one examples \\(X\\) numbers fit rule want know probable new number \\(y\\) also fits rule.model discussed can naturally extended problem. likelihood, can make strong sampling assumption .prior things get little trickier. Intuitively concepts like ‚Äúeven numbers‚Äù seem probable even seeing examples concepts like ‚Äúmultiples 7.‚Äù now becomes psychological question: rules people find intuitively plausible? single way decide , run survey find : Give people long list rules ask judge intuitively natural seem. construct prior probability distribution using data.Alternatively, come definition ‚Äúcomplexity‚Äù hypotheses assume less complex hypotheses receive higher prior probability.chosen prior probability distribution \\(P(h)\\), can now proceed just .","code":""},{"path":"generalization.html","id":"inductive-generalizations-about-animal-properties","chapter":"4 Generalization","heading":"4.3 Inductive generalizations about animal properties üê¥","text":"Now let‚Äôs consider even complex generalization problem, based 2002 paper Neville Sanjana Josh Tenenbaum2. problem generalizing properties set example animals animals. paper uses following example:way read follows: premises state chimps squirrels blicketitis. conclusion horses blicketitis. inductive generalization question probable conclusion given premises? Intuitively, conclusion example seems plausible conclusion following example:interesting psychological question generalizations seem intuitively plausible others?","code":"Chimps have blicketitis\nSquirrels have blicketitis\n--------------------------\nHorses have blicketitisChimps have blicketitis\nGorillas have blicketitis\n--------------------------\nHorses have blicketitis"},{"path":"generalization.html","id":"hypothesis-space","chapter":"4 Generalization","heading":"4.3.1 Hypothesis space","text":"problem conceptually similar ones ‚Äôve already discussing. want infer animals blicketitis seeing examples animals blicketitis. first question answer analogue consequential region problem. Animals don‚Äôt naturally fall one-dimensional interval ‚Äôll need define different hypothesis space. One possibility hierarchy, naturally captures knowledge people animals.","code":""},{"path":"generalization.html","id":"clustering","chapter":"4 Generalization","heading":"4.3.1.1 Clustering","text":"paper first creates hierarchy eight animals using similarity data collected people. Specifically, asked people judge similar pairs eight animals calculated average similarity judgment animal.similarity judgments can used construct tree using simple clustering algorithm. algorithm works follows:Put animals cluster.one cluster hasn‚Äôt placed group, following:\nIdentify pair clusters greatest similarity .\nGroup clusters new cluster.\nIdentify pair clusters greatest similarity .Group clusters new cluster.several approaches computing similarity two clusters contain multiple animals. example, might use maximum similarity pair individual animals two clusters.results algorithm can represented tree, shown . node tree represents cluster. hypotheses consider combination 1, 2, 3 clusters determined using clustering algorithm.\nFigure 4.2: tree animal species. Image Sanjana & Tenenbaum (2002).\n","code":""},{"path":"generalization.html","id":"the-model","chapter":"4 Generalization","heading":"4.3.2 The model","text":"can now define model. First, let‚Äôs define \\(P(h)\\) \\(h\\) set clusters. authors make assumption analogous following:\\[\nP(h) \\propto \\frac{1}{\\phi^k}\n\\]\n\\(k\\) number clusters \\(h\\). \\(\\phi\\) parameter can choose. long \\(\\phi > 1\\), \\(P(h)\\) smaller hypotheses consisting clusters. effect assigning higher weight ‚Äúsimpler‚Äù hypotheses., make strong sampling assumption likelihood. time, \\(|h|\\) number animal species \\(h\\) \\(n\\) number examples premises.consequence assumptions something like Occam‚Äôs razor says simplest explanation preferred. model assign 0 likelihood hypotheses don‚Äôt include \\(X\\), thus narrowing hypothesis space just hypotheses possible. , favor hypotheses fewer clusters fewer animals. words, favor simplest hypotheses consistent examples ‚Äôve seen.","code":""},{"path":"generalization.html","id":"try-out-the-model-yourself","chapter":"4 Generalization","heading":"4.3.3 Try out the model yourself","text":"can try running version model making copy code . , let‚Äôs look model handles specific cases.Let‚Äôs start single example: horses can get blicketitis., see standard generalization curve. Now, let‚Äôs add animals.Now model increased probability animals. makes sense reason think blicketitis might affect lots different animals.Adding squirrel supported idea. add additional examples animals ‚Äôve already seen?Now probabilities animals drop, ‚Äôs starting look like maybe disease affects four animals ‚Äôve seen far.sum , ‚Äôve seen small number examples, like single horse, model generally prefer simpler hypotheses. ‚Äôve seen data, favor complex hypotheses (like group animals two separate evolutionary clusters) data support .one final example, let‚Äôs look specific impact multiple examples single animal., see model becomes increasingly confident property unique gorillas. makes intuitive sense ‚Äôs something people seem exhibit judgments. , point paper, ‚Äôs something non-probabilistic models can easily explain.","code":"animalGeneralization([\"horse\"])## array([1.        , 0.52984834, 0.30628906, 0.30628906, 0.19579428,\n##        0.19579428, 0.12893614, 0.12893614, 0.0842413 , 0.0842413 ])animalGeneralization([\"horse\", \"cow\", \"mouse\"])## array([1.        , 1.        , 0.57379051, 0.57379051, 0.47852518,\n##        0.47852518, 1.        , 0.60980466, 0.1707609 , 0.1707609 ])animalGeneralization([\"horse\", \"cow\", \"mouse\", \"squirrel\"])## array([1.        , 1.        , 0.64983602, 0.64983602, 0.58531333,\n##        0.58531333, 1.        , 1.        , 0.18405475, 0.18405475])animalGeneralization([\"horse\", \"cow\", \"mouse\", \"squirrel\", \"horse\", \"squirrel\"])## array([1.        , 1.        , 0.32551484, 0.32551484, 0.26938358,\n##        0.26938358, 1.        , 1.        , 0.06883892, 0.06883892])animalGeneralization([\"gorilla\"])## array([0.22011594, 0.22011594, 0.22011594, 0.22011594, 0.46663258,\n##        1.        , 0.13668495, 0.13668495, 0.08643809, 0.08643809])animalGeneralization([\"gorilla\", \"gorilla\"])## array([0.06236149, 0.06236149, 0.06236149, 0.06236149, 0.2473422 ,\n##        1.        , 0.03994508, 0.03994508, 0.02971748, 0.02971748])animalGeneralization([\"gorilla\", \"gorilla\", \"gorilla\"])## array([0.01730482, 0.01730482, 0.01730482, 0.01730482, 0.1259028 ,\n##        1.        , 0.01270155, 0.01270155, 0.01111944, 0.01111944])"},{"path":"generalization.html","id":"results","chapter":"4 Generalization","heading":"4.3.4 Results","text":"results paper show model predicts people‚Äôs judgments quite well, better alternative models rely Bayesian inference. results suggest assumptions model similar assumptions people make making inductive generalizations.\nFigure 4.3: Comparison model results human judgments. Image Sanjana & Tenenbaum (2002).\n","code":""},{"path":"categorization.html","id":"categorization","chapter":"5 Categorization","heading":"5 Categorization","text":"last chapter introduced problem inductive generalization. chapter focus specific case generalization particular interest psychologists, cognitive scientists, people use AI machine learning: classification categorization. Basically, assigning labels things.People constantly classify things world categories (chairs, cats, friends, enemies, edible things, ). helps us communicate function novel situations.machine learning, ‚Äôs often useful classify inputs different categories like whether social media post violates community standards , whether image contains human face , whether MRI contains tumor.Psychologists study people form categories provides window organize knowledge. basic problem one studied machine learning.‚Äôm going intrdouce fairly simple psychological model categorization introduced Robert Nosofsky called Generalized Context Model. assumes people make classification judgments using following general algorithm:Remember examples categories ‚Äôve seen .want classify new instance, compare previous examples different categories rate similar one.Assign category highest average similarity.model makes outlandish assumptions (like idea people remember every example seen ). , first approximation, decent job predicting people‚Äôs classification judgments lot situations. learning purposes, advantage pretty easy understand implement.","code":""},{"path":"categorization.html","id":"a-typical-category-learning-experiment","chapter":"5 Categorization","heading":"5.1 A typical category learning experiment üü¢üü®","text":"psychology, category learning experiments pretty similar structure. People see unfamiliar stimuli differ several dimensions can sorted different categories. task learn distinguishes one category another. experiments usually consist two phases: training phase, testing phase.Training phase: People see many examples category classify , often simply guessing first. get feedback gradually learn tell different categories apart.Testing phase: People see examples, usually brand new ones, classify . time don‚Äôt get feedback. point phase test people actually learned meaning categories.stimuli abstract shapes, cartoon insects, race cars different features, anything else. matters clearly distinguishable features.","code":""},{"path":"categorization.html","id":"representing-stimuli-in-a-model","chapter":"5 Categorization","heading":"5.2 Representing stimuli in a model üß©","text":"modeling purposes, types stimuli (discrete-valued features) can represented matrix, following properties:dimension matrix represents different feature stimuli.length dimension represents many different values feature can .single item can represented binary matrix 1s cells indicating feature values 0s everywhere else.example, Robert Nosofsky‚Äôs (1986) test GCM3, stimuli semicircles lines . two feature dimensions (1) circle size (2) line orientation. feature four possible values.Using binary matrix representation, one possible stimulus Nosofsky experiment:Nosofksy stimuli pretty simple: can exactly one value dimension, representation always single 1 matrix.wanted know many stimulus present model, pretty cumbersome maintain long list arrays like one. instead maintain single matrix stores counts stimuli. , values element represent number stimuli observed feature values.example, let‚Äôs consider ‚Äúdimensional‚Äù condition Nosofsky‚Äôs experiment, subjects saw stimuli ‚Äúdiagonals‚Äù matrix. Let‚Äôs assume saw one 100 times (actually, mind-numbing 1200 trials 2600 practice trials ü•¥). represent like :still isn‚Äôt ideal though. doesn‚Äôt represent category labels subjects got training. don‚Äôt know examples belonged categories.Thinking ahead GCM works, let‚Äôs instead represent training examples like list, can iterate :format, row matrix array three elements. first element category label: 1 2. second two elements indices stimulus matrix. Note: ‚Äôve deviated Python norms consistent numbering table original Nosofsky paper, shown . working model, remember indexing Python starts 0.\nFigure 5.1: Training examples dimensional condition. Image Nosofsky (1986).\n","code":"import numpy as np\n\nstimulus = np.array([[0, 0, 0, 0],\n                     [0, 0, 0, 0],\n                     [0, 0, 1, 0],\n                     [0, 0, 0, 0]], dtype=int)\nprint(stimulus)## [[0 0 0 0]\n##  [0 0 0 0]\n##  [0 0 1 0]\n##  [0 0 0 0]]training_set = np.array([[100, 0, 0, 100],\n                         [0, 100, 100, 0],\n                         [0, 100, 100, 0],\n                         [100, 0, 0, 100]], dtype=int)\nprint(training_set)## [[100   0   0 100]\n##  [  0 100 100   0]\n##  [  0 100 100   0]\n##  [100   0   0 100]]tDimensional = np.zeros((8,3), dtype=int)\ntDimensional[0] = [1,1,1]\ntDimensional[1] = [1,2,2]\ntDimensional[2] = [1,3,2]\ntDimensional[3] = [1,4,1]\ntDimensional[4] = [2,1,4]\ntDimensional[5] = [2,2,3]\ntDimensional[6] = [2,3,3]\ntDimensional[7] = [2,4,4]\n\nprint(tDimensional)## [[1 1 1]\n##  [1 2 2]\n##  [1 3 2]\n##  [1 4 1]\n##  [2 1 4]\n##  [2 2 3]\n##  [2 3 3]\n##  [2 4 4]]"},{"path":"categorization.html","id":"the-generalized-context-model-gcm","chapter":"5 Categorization","heading":"5.3 The Generalized Context Model (GCM)","text":", describe special case model applies tasks (like one paper) two categories. However, model can easily extended number categories. model defined two key equations.first equation defines probability classifying Stimulus \\(S_i\\) Category \\(C_1\\) (.e., Category 1):\\[\n\\begin{equation}\nP(C_1|S_i) = \\frac{b_1 \\sum_{j \\C_1} \\eta_{ij}}{b_1 \\sum_{j \\C_1} \\eta_{ij} + (1-b_1) \\sum_{k \\C_2} \\eta_{ik}}\n\\tag{5.1}\n\\end{equation}\n\\]sum \\(\\sum_{j \\C_1}\\) sum stimuli \\(S_j\\) belong Category 1. sum \\(\\sum_{j \\C_1}\\) sum stimuli \\(S_k\\) belong Category 2.Equation (5.1) parameter \\(b_1\\) defined response bias Category 1. \\(b_1\\) can range 0 1 captures possibility subject biased respond one category another. similar identical prior distribution. \\(b_1\\) small, model biased toward Category 2; \\(b_1\\) large, model biased toward Category 1. Note \\(b = 0.5\\), cancels equation.also include response bias Category 2, model assumes \\(\\sum_i b_i = 1\\). Therefore, two categories, \\(b_2 = 1 - b_1\\) see second term denominator Equation (5.1).\\(\\eta_{ij}\\) function defines similar \\(S_i\\) \\(S_j\\) . GCM assumes stimuli can represented points multi-dimensional space (case, two-dimensional space) similarity defined function distance two points:\\[\n\\eta_{ij} = e^{-c^2 \\left[w_1 (f_{i1} - f_{j1})^2 + (1-w_1)(f_{i2} - f_{j2})^2 \\right]}\n\\]\\(f_{i1}\\) \\(f_{i2}\\) refer feature values dimensions 1 2 \\(S_i\\). equation two parameters: \\(c\\) \\(w_1\\). \\(c\\) scaling parameter affects steeply exponential curve . allow us account different people might different ideas close two stimuli must called similar. \\(w_1\\) called attentional weight dimension 1. parameter captures much weight placed dimension 1 dimension 2. Just like \\(b_1\\), \\(w_1\\) can range 0 1, larger , weight placed dimension 1. Similarly, add \\(w_2\\), attention weights constrained sum 1.","code":""},{"path":"categorization.html","id":"generating-model-predictions","chapter":"5 Categorization","heading":"5.3.1 Generating model predictions","text":"order generate predictions model, need two things. First, need define training stimuli , feature values . allow us compute sums Equation (5.1).Next, need specify values 3 parameters \\(b_1\\), \\(c\\), \\(w_1\\). Nosofsky first collecting data people experiment. , every stimulus \\(S_i\\) can record proportion times people classified Category 1. words, can collect empirical estimates \\(P(C_1|S_i)\\) values \\(S_i\\).Nosofsky uses maximum likelihood procedure fitting model data. Conceptually, idea find set values three parameters produce model predictions close possible empirical data. (exactly linear regression works, data \\((\\bar{x},\\bar{y})\\) want find best-fitting values \\(\\) \\(b\\) function \\(y = ax + b\\) describes relationship \\(x\\) \\(y\\).)can define model fit mean squared error (MSE). MSE defined \\[\n\\frac{1}{n} \\sum_i (y_i - x_i)^2\n\\]\\(y\\) data \\(x\\) model predictions. lower MSE means better model fit. Finding best values parameters can achieved exhaustive search values. example, might consider possible values parameter increments 0.1. write program performs following basic algorithm:Set minimum MSE \\(\\inf\\).possible values \\(b_1\\), \\(c\\), \\(w_1\\):\nGenerate model predictions \\(P(R_1|S_i)\\) \\(S_i\\).\nCompute MSE empirical data model predictions generated previous step.\nMSE smaller minimum MSE, set minimum MSE current value store current values \\(b_1\\), \\(c\\), \\(w_1\\).\nGenerate model predictions \\(P(R_1|S_i)\\) \\(S_i\\).Compute MSE empirical data model predictions generated previous step.MSE smaller minimum MSE, set minimum MSE current value store current values \\(b_1\\), \\(c\\), \\(w_1\\).Return stored values \\(b_1\\), \\(c\\), \\(w_1\\).","code":""},{"path":"categorization.html","id":"homework-3","chapter":"5 Categorization","heading":"5.3.2 Homework 3","text":"next homework implement GCM described . homework, encode training test stimuli implement equations model-fitting algorithm . Additionally, get experience behavioral side cognitive science, create working version category learning experiment order collect data can use compare GCM‚Äôs predictions.","code":""},{"path":"hierarchical-generalization.html","id":"hierarchical-generalization","chapter":"6 Hierarchical generalization","heading":"6 Hierarchical generalization","text":"previous examples, always finite number hypotheses making inferences (number black balls, fair trick coin, yellow green taxi). Sometimes, want consider infinite set hypotheses. example, flipping coin, probability coin coming heads? answer question number interval [0,1].","code":""},{"path":"hierarchical-generalization.html","id":"the-beta-binomial-model","chapter":"6 Hierarchical generalization","heading":"6.1 The Beta-Binomial model ü™ô","text":"\nFigure 6.1: Photo ZSun Fu Unsplash.\ncan answer question model called Beta-Binomial model, named probability distributions uses. First, let‚Äôs set basic assumptions model.Let \\(P(\\text{heads}) = \\theta\\). don‚Äôt know \\(\\theta\\) . observing sequence coin flips \\(D\\), want estimate \\(\\theta\\). can accomplished directly applying Bayes‚Äôs rule:\\[\nP(\\theta|D) = \\frac{P(D|\\theta) P(\\theta)}{P(D)}\n\\]data \\(D\\) case corresponds number \\(k\\) heads \\(n\\) total flips. follows Binomial distribution, describes probability getting \\(k\\) successes \\(n\\) trials, probability success trial \\(\\theta\\). define heads ‚Äúsuccess.‚Äù\\[\n\\begin{align}\nP(d|\\theta) = P(k|\\theta,n) &= \\text{Bin}(k; n, \\theta) \\\\\n&= \\binom{n}{k} \\theta^{k} (1-\\theta)^{n-k}\n\\end{align}\n\\]notation \\(\\text{Bin}(\\cdot)\\) function indicates distribution \\(k\\) (number successes) distribution parameters \\(n\\) (total number trials) \\(\\theta\\) (probability success trial).can define prior, \\(P(\\theta)\\), however like. \\(\\theta\\) random variable can take value 0 1, just say \\(P(\\theta) = 0.5\\) like earlier examples. Instead, \\(P(\\theta)\\) must probability distribution assigns probabilities value 0 1. know nothing \\(\\theta\\), use Uniform(\\([0,1]\\)) non-informative prior assigns equal probability values \\(\\theta\\).Alternatively, convenient choice (reasons explained ) \\(P(\\theta)\\) Beta distribution:\\[\nP(\\theta) = \\text{Beta}(\\theta;\\alpha,\\beta)\n\\]Beta distribution two parameters: \\(\\alpha > 0\\) \\(\\beta > 0\\). Let‚Äôs create function allow us visualize Beta distribution.plot_beta takes two arguments: (\\(\\alpha\\)), b(\\(\\beta\\)) plots Beta distribution parameter values.Let‚Äôs see looks like different values.\\(\\alpha = \\beta = 1\\), Beta distribution identical Uniform(\\([0,1]\\)) distribution.\\(\\alpha\\) \\(\\beta\\) greater 1 equal, get distribution peak around 0.5. strong prior expectations coin unbiased, increase parameters even :\\(\\alpha\\) \\(\\beta\\) equal?Now, \\(\\alpha\\) \\(\\beta\\) less 1?","code":"from scipy import stats\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_beta(a, b):\n  x = np.linspace(0,1,num=500)\n  px = stats.beta.pdf(x, a, b)\n  \n  fig, ax = plt.subplots()\n  ax.plot(x, px)\n  plt.show()plot_beta(1,1)plot_beta(3,3)plot_beta(50,50)plot_beta(4,2)plot_beta(0.5,0.5)"},{"path":"hierarchical-generalization.html","id":"conjugate-distributions","chapter":"6 Hierarchical generalization","heading":"6.1.1 Conjugate distributions","text":"Beta distribution conjugate distribution Binomial distribution. means likelihood Binomial distribution prior Beta distribution, posterior also Beta distribution. Specifically, making assumptions,\\[\nP(\\theta|D) = \\text{Beta}(\\theta; \\alpha + k, \\beta + n-k)\n\\]parameters posterior distribution (1) sum \\(\\alpha\\) prior number observed heads (2) sum \\(\\beta\\) prior number observed tails. means parameters \\(\\alpha\\) \\(\\beta\\) Beta prior natural interpretation ‚Äúvirtual‚Äô‚Äô flips.‚Äù example, larger \\(\\alpha\\) compared \\(\\beta\\), biased toward heads expect \\(\\theta\\) . Additionally, larger \\(\\alpha\\) \\(\\beta\\) , certain (less diffuse) prior .","code":""},{"path":"hierarchical-generalization.html","id":"parameter-estimation","chapter":"6 Hierarchical generalization","heading":"6.1.2 Parameter estimation","text":"used conjugate distribution, can use plot_beta function generate posterior probability distributions coin flips.Suppose start fairly strong belief coin fair, represented distribution:wasn‚Äôt totally realistic, though. picked coin ground, prior beliefs bias probably look like :\nhappens now flipped coin 20 times came heads every time?","code":"plot_beta(30,30)plot_beta(30+20,30)plot_beta(2000,2000)plot_beta(2000+20,2000)"},{"path":"hierarchical-generalization.html","id":"overhypotheses","chapter":"6 Hierarchical generalization","heading":"6.2 Overhypotheses","text":"Flip 19 coins row come heads. probability 20th coin comes heads. higher 0.5. ?","code":""},{"path":"hierarchical-generalization.html","id":"the-shape-bias","chapter":"6 Hierarchical generalization","heading":"6.2.1 The shape bias","text":"","code":""},{"path":"hierarchical-generalization.html","id":"kemp-et-al-introduction-and-results","chapter":"6 Hierarchical generalization","heading":"6.3 Kemp et al introduction and results","text":"","code":""}]
