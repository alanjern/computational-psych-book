<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 8 Social cognition | Introduction to Computational Psychology</title>
<meta name="author" content="Alan Jern">
<meta name="description" content="Watch the video below. What do you see?  If you‚Äôre like most people, you see more than just lifeless shapes moving around. You see a whole drama play out involving characters with goals and...">
<meta name="generator" content="bookdown 0.25 with bs4_book()">
<meta property="og:title" content="Chapter 8 Social cognition | Introduction to Computational Psychology">
<meta property="og:type" content="book">
<meta property="og:url" content="https://alanjern.github.io/computational-psych-book/social-cognition.html">
<meta property="og:image" content="https://alanjern.github.io/computational-psych-book/images/cover/marble_notext.jpg">
<meta property="og:description" content="Watch the video below. What do you see?  If you‚Äôre like most people, you see more than just lifeless shapes moving around. You see a whole drama play out involving characters with goals and...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 8 Social cognition | Introduction to Computational Psychology">
<meta name="twitter:description" content="Watch the video below. What do you see?  If you‚Äôre like most people, you see more than just lifeless shapes moving around. You see a whole drama play out involving characters with goals and...">
<meta name="twitter:image" content="https://alanjern.github.io/computational-psych-book/images/cover/marble_notext.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><link rel="apple-touch-icon" sizes="180x180" href="images/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="images/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="images/favicons/favicon-16x16.png">
<link rel="manifest" href="images/favicons/site.webmanifest">
<link rel="shortcut icon" href="images/favicons/favicon.ico">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="images/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Introduction to Computational Psychology</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="intro.html"><span class="header-section-number">1</span> Why computational modeling?</a></li>
<li><a class="" href="bayes.html"><span class="header-section-number">2</span> Bayesian inference</a></li>
<li><a class="" href="generalization.html"><span class="header-section-number">3</span> Generalization</a></li>
<li><a class="" href="categorization.html"><span class="header-section-number">4</span> Categorization</a></li>
<li><a class="" href="hierarchical-generalization.html"><span class="header-section-number">5</span> Hierarchical generalization</a></li>
<li><a class="" href="sampling-assumptions.html"><span class="header-section-number">6</span> Sampling assumptions</a></li>
<li><a class="" href="pragmatics.html"><span class="header-section-number">7</span> Language pragmatics</a></li>
<li><a class="active" href="social-cognition.html"><span class="header-section-number">8</span> Social cognition</a></li>
<li><a class="" href="iterated-learning.html"><span class="header-section-number">9</span> Iterated learning</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/alanjern/computational-psych-book">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="social-cognition" class="section level1" number="8">
<h1>
<span class="header-section-number">8</span> Social cognition<a class="anchor" aria-label="anchor" href="#social-cognition"><i class="fas fa-link"></i></a>
</h1>
<p>Watch the video below. What do you see?</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/VTNmLt7QX8E" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>If you‚Äôre like most people, you see more than just lifeless shapes moving around. You see a whole drama play out involving characters with goals and emotions.</p>
<p>This animation, from a <a href="https://psycnet.apa.org/doi/10.2307/1416950">1944 study by Heider and Simmel</a>, is an excellent example of our capacity for <em>social cognition</em>: thinking about other people. <strong>We are constantly attributing goals, beliefs, desires, and feelings to others.</strong> The fact that we are willing to do it for simple shapes suggests we may not be able to help ourselves from doing it.</p>
<p>When someone takes an action, makes a decision, or makes a facial expression, how do we infer what they‚Äôre thinking or feeling? In this chapter, we‚Äôll look at two computational approaches to answering this question.</p>
<div id="inverse-decision-making" class="section level2" number="8.1">
<h2>
<span class="header-section-number">8.1</span> Inverse decision-making üçë<a class="anchor" aria-label="anchor" href="#inverse-decision-making"><i class="fas fa-link"></i></a>
</h2>
<p>All social cognition problems have the same basic character: you <em>observe</em> something about other people, and you want to <em>infer</em> some underlying cause of the thing you observed. For example, you see someone take an action, and you want to infer the goal that motivated the action.</p>
<p>The basic idea behind many approaches to understanding how people reason about other people is that they have some kind of mental model of how other people act and they essentially run that model backward (or invert) the model to infer the information they don‚Äôt get to see.</p>
<p>Consider a simple decision-making situation. Rue likes peaches more than oranges and oranges more than apples:</p>
<blockquote>
<p>üçë &gt; üçä &gt; üçé</p>
</blockquote>
<p>Now you give Rue a choice between these three fruits. Which one is she most likely to choose?</p>
<p>Probably the peach right? I mean, she might choose the orange or the apple because she happens to be in the mood for one of those, but given the information you have, the peach is a good guess.</p>
<p>Now imagine you don‚Äôt know Rue‚Äôs fruit preferences. She‚Äôs offered the following fruits to pick from:</p>
<blockquote>
<p>üçë üçä üçé</p>
</blockquote>
<p>She chooses the peach üçë. If you had to guess her relative preferences for the fruits, what would you think?</p>
<p>At the very least, you might guess she likes peaches more than oranges and apples. But why?</p>
<p>You assume that people‚Äôs choices are guided by <em>preferences</em> and that people‚Äôs actions are basically <em>rational</em>. So seeing Rue make one choice from a set of options gives you information about what she likes.</p>
<p>Can we formalize this intuition?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;The following is based on &lt;a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0092160"&gt;a model originally developed by Chris Lucas and his collaborators&lt;/a&gt;.&lt;/p&gt;'><sup>4</sup></a></p>
<div id="a-preference-learning-model" class="section level3" number="8.1.1">
<h3>
<span class="header-section-number">8.1.1</span> A preference learning model<a class="anchor" aria-label="anchor" href="#a-preference-learning-model"><i class="fas fa-link"></i></a>
</h3>
<p>Let‚Äôs start with some assumptions:</p>
<ul>
<li>Each fruit provides some utility to the person who takes it (recall the notion of utility introduced in <a href="pragmatics.html#pragmatics">Chapter 7</a>).</li>
<li>Utilities are additive, meaning two peaches provide twice as much utility as one peach.</li>
<li>People will choose options <em>in proportion</em> to their utility. This is the same ‚Äúsoftmax‚Äù assumption we used in <a href="pragmatics.html#rsa-model">the rational speech act model</a>.</li>
</ul>
<p>These assumptions combine to give us a <em>choice model</em>, a model of how people will make choices between different options. (We‚Äôve limited our focus to fruits, but the model could be applied to anything.)</p>
<p><span class="math display" id="eq:choicemodel">\[
\begin{equation}
p(c = o_j|\mathbf{u}, \mathbf{A}) = \frac{\exp(U_j)}{\sum^n_{k=1}\exp(U_k)}
\tag{8.1}
\end{equation}
\]</span></p>
<p>In this model, <span class="math inline">\(c\)</span> is the choice, <span class="math inline">\(o_j\)</span> refers to option <span class="math inline">\(j\)</span>, <span class="math inline">\(\mathbf{A}\)</span> is a vector specifying each option and their attributes (or features), <span class="math inline">\(\mathbf{u}\)</span> is a vector of utilities that the decision-maker assigns to each attribute, and <span class="math inline">\(U_j\)</span> is the summed total utility in each option.</p>
<div id="inverting-the-choice-model" class="section level4" number="8.1.1.1">
<h4>
<span class="header-section-number">8.1.1.1</span> Inverting the model<a class="anchor" aria-label="anchor" href="#inverting-the-choice-model"><i class="fas fa-link"></i></a>
</h4>
<p>Remember that our goal is to <em>infer other people‚Äôs preferences</em>, not predict their choices. So, after we see someone make a choice between some fruits, how do we infer what fruits they like best? We can invert Equation <a href="social-cognition.html#eq:choicemodel">(8.1)</a> using Bayes‚Äôs rule:</p>
<p><span class="math display" id="eq:idmmodel">\[
\begin{equation}
p(\mathbf{u}|c,\mathbf{A}) = \frac{p(c|\mathbf{u},\mathbf{A})p(\mathbf{u})}{p(c|\mathbf{A})}
\tag{8.2}
\end{equation}
\]</span></p>
<p>Suppose Rue has a choice between the following options:</p>
<blockquote>
<p>Option 1: üçë üçé üçä</p>
<p>Option 2: üçå</p>
</blockquote>
<p>Jules has a choice between the following options:</p>
<blockquote>
<p>Option 1: üçë</p>
<p>Option 2: üçé üçä üçå</p>
</blockquote>
<p>Both Rue and Jules pick Option 1, which includes a peach üçë. Based on their choices alone, who do you think likes peaches more? (Or, at least, which person‚Äôs choice would make you more confident they like peaches?)</p>
<p>Let‚Äôs apply the inverse decision-making model to these two choices.</p>
<p>We‚Äôll start by encoding these choices using a binary encoding scheme in which each element in a list represents a fruit and this element is set to 1 if that fruit is present in the option.</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="social-cognition.html#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb79-2"><a href="social-cognition.html#cb79-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-3"><a href="social-cognition.html#cb79-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Fruit order:</span></span>
<span id="cb79-4"><a href="social-cognition.html#cb79-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. peach</span></span>
<span id="cb79-5"><a href="social-cognition.html#cb79-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. apple</span></span>
<span id="cb79-6"><a href="social-cognition.html#cb79-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. orange</span></span>
<span id="cb79-7"><a href="social-cognition.html#cb79-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. banana</span></span>
<span id="cb79-8"><a href="social-cognition.html#cb79-8" aria-hidden="true" tabindex="-1"></a>choice_rue <span class="op">=</span> np.array([[<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>],</span>
<span id="cb79-9"><a href="social-cognition.html#cb79-9" aria-hidden="true" tabindex="-1"></a>                       [<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>]])</span>
<span id="cb79-10"><a href="social-cognition.html#cb79-10" aria-hidden="true" tabindex="-1"></a>choice_jules <span class="op">=</span> np.array([[<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>],</span>
<span id="cb79-11"><a href="social-cognition.html#cb79-11" aria-hidden="true" tabindex="-1"></a>                         [<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>]])</span></code></pre></div>
<p>Let‚Äôs define a function that calculates the choice probability in Equation <a href="social-cognition.html#eq:choicemodel">(8.1)</a>. This is our likelihood function.</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="social-cognition.html#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_choice_prob(j, u, options): </span>
<span id="cb80-2"><a href="social-cognition.html#cb80-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">'''Returns the probability of choosing option j</span></span>
<span id="cb80-3"><a href="social-cognition.html#cb80-3" aria-hidden="true" tabindex="-1"></a><span class="co">     from the set options.</span></span>
<span id="cb80-4"><a href="social-cognition.html#cb80-4" aria-hidden="true" tabindex="-1"></a><span class="co">     </span></span>
<span id="cb80-5"><a href="social-cognition.html#cb80-5" aria-hidden="true" tabindex="-1"></a><span class="co">     Parameters:</span></span>
<span id="cb80-6"><a href="social-cognition.html#cb80-6" aria-hidden="true" tabindex="-1"></a><span class="co">       j (int): the chosen option</span></span>
<span id="cb80-7"><a href="social-cognition.html#cb80-7" aria-hidden="true" tabindex="-1"></a><span class="co">       u (array): a vector of utilities assigned to the</span></span>
<span id="cb80-8"><a href="social-cognition.html#cb80-8" aria-hidden="true" tabindex="-1"></a><span class="co">         attributes in the options</span></span>
<span id="cb80-9"><a href="social-cognition.html#cb80-9" aria-hidden="true" tabindex="-1"></a><span class="co">       options (array): a matrix in which each row is an</span></span>
<span id="cb80-10"><a href="social-cognition.html#cb80-10" aria-hidden="true" tabindex="-1"></a><span class="co">         option, and each option is a binary array of the </span></span>
<span id="cb80-11"><a href="social-cognition.html#cb80-11" aria-hidden="true" tabindex="-1"></a><span class="co">         attributes in that option</span></span>
<span id="cb80-12"><a href="social-cognition.html#cb80-12" aria-hidden="true" tabindex="-1"></a><span class="co">         </span></span>
<span id="cb80-13"><a href="social-cognition.html#cb80-13" aria-hidden="true" tabindex="-1"></a><span class="co">     Returns:</span></span>
<span id="cb80-14"><a href="social-cognition.html#cb80-14" aria-hidden="true" tabindex="-1"></a><span class="co">       p (float): probability of choosing option j</span></span>
<span id="cb80-15"><a href="social-cognition.html#cb80-15" aria-hidden="true" tabindex="-1"></a><span class="co">  '''</span></span>
<span id="cb80-16"><a href="social-cognition.html#cb80-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb80-17"><a href="social-cognition.html#cb80-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the total utility of each option</span></span>
<span id="cb80-18"><a href="social-cognition.html#cb80-18" aria-hidden="true" tabindex="-1"></a>  total_u <span class="op">=</span> np.<span class="bu">sum</span>(u<span class="op">*</span>options, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb80-19"><a href="social-cognition.html#cb80-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb80-20"><a href="social-cognition.html#cb80-20" aria-hidden="true" tabindex="-1"></a>  p <span class="op">=</span> np.exp(total_u[j]) <span class="op">/</span> np.<span class="bu">sum</span>(np.exp(total_u))</span>
<span id="cb80-21"><a href="social-cognition.html#cb80-21" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>(p)</span></code></pre></div>
<p>Let‚Äôs first assume they both like all fruits equally (they get a utility of 1 from any fruit). What is the probability of Rue and Jules making these choices?</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb81-1"><a href="social-cognition.html#cb81-1" aria-hidden="true" tabindex="-1"></a>utilities <span class="op">=</span> np.array([<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>])</span>
<span id="cb81-2"><a href="social-cognition.html#cb81-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-3"><a href="social-cognition.html#cb81-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Rue's choice probability:"</span> <span class="op">+</span> </span>
<span id="cb81-4"><a href="social-cognition.html#cb81-4" aria-hidden="true" tabindex="-1"></a>  <span class="bu">str</span>(compute_choice_prob(<span class="dv">0</span>, utilities, choice_rue)))</span></code></pre></div>
<pre><code>## Rue's choice probability:0.8807970779778824</code></pre>
<div class="sourceCode" id="cb83"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="social-cognition.html#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Jules's choice probability:"</span> <span class="op">+</span> </span>
<span id="cb83-2"><a href="social-cognition.html#cb83-2" aria-hidden="true" tabindex="-1"></a>  <span class="bu">str</span>(compute_choice_prob(<span class="dv">0</span>, utilities, choice_jules)))</span></code></pre></div>
<pre><code>## Jules's choice probability:0.11920292202211755</code></pre>
<p>Unsurprisingly, Rue‚Äôs choice is much more probable. What if they like peaches four times as much as other fruits?</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="social-cognition.html#cb85-1" aria-hidden="true" tabindex="-1"></a>utilities <span class="op">=</span> np.array([<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>])</span>
<span id="cb85-2"><a href="social-cognition.html#cb85-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-3"><a href="social-cognition.html#cb85-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Rue's choice probability:"</span> <span class="op">+</span> </span>
<span id="cb85-4"><a href="social-cognition.html#cb85-4" aria-hidden="true" tabindex="-1"></a>  <span class="bu">str</span>(compute_choice_prob(<span class="dv">0</span>, utilities, choice_rue)))</span></code></pre></div>
<pre><code>## Rue's choice probability:0.9933071490757152</code></pre>
<div class="sourceCode" id="cb87"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb87-1"><a href="social-cognition.html#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Jules's choice probability:"</span> <span class="op">+</span> </span>
<span id="cb87-2"><a href="social-cognition.html#cb87-2" aria-hidden="true" tabindex="-1"></a>  <span class="bu">str</span>(compute_choice_prob(<span class="dv">0</span>, utilities, choice_jules)))</span></code></pre></div>
<pre><code>## Jules's choice probability:0.7310585786300048</code></pre>
<p>This increases Rue‚Äôs choice probability by just over 10%, but it increases Jules‚Äôs choice probability by over 60%.</p>
<p>To invert the model, we also need to specify the prior probability, <span class="math inline">\(p(\mathbf{u})\)</span>. We‚Äôll assume that people generally like fruit, but they are likely to disagree about how much they like different fruits, and there‚Äôs a possibility that some people will dislike like certain fruits.</p>
<p>We can capture this idea by assuming that utilities for fruits are normally distributed with a positive mean. Let‚Äôs say that they have a mean of 2 and a standard deviation of 0.5:</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb89-1"><a href="social-cognition.html#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb89-2"><a href="social-cognition.html#cb89-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb89-3"><a href="social-cognition.html#cb89-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-4"><a href="social-cognition.html#cb89-4" aria-hidden="true" tabindex="-1"></a>u_mean <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb89-5"><a href="social-cognition.html#cb89-5" aria-hidden="true" tabindex="-1"></a>u_sd <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb89-6"><a href="social-cognition.html#cb89-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-7"><a href="social-cognition.html#cb89-7" aria-hidden="true" tabindex="-1"></a>u <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">1</span>,<span class="dv">5</span>,<span class="dv">1000</span>)</span>
<span id="cb89-8"><a href="social-cognition.html#cb89-8" aria-hidden="true" tabindex="-1"></a>pu <span class="op">=</span> norm.pdf(u,u_mean,u_sd)</span>
<span id="cb89-9"><a href="social-cognition.html#cb89-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-10"><a href="social-cognition.html#cb89-10" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb89-11"><a href="social-cognition.html#cb89-11" aria-hidden="true" tabindex="-1"></a>ax.plot(u, pu)</span>
<span id="cb89-12"><a href="social-cognition.html#cb89-12" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"u"</span>)</span>
<span id="cb89-13"><a href="social-cognition.html#cb89-13" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"Prior probability of u"</span>)</span>
<span id="cb89-14"><a href="social-cognition.html#cb89-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-15"><a href="social-cognition.html#cb89-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="inline-figure"><img src="_main_files/figure-html/unnamed-chunk-63-11.png" width="672"></div>
<p>Additionally, we‚Äôll make the simplifying assumption that utilities for different fruits are <em>independent</em>. This means that knowing someone likes pineapples doesn‚Äôt tell you anything about how much they‚Äôll like grapefruits.</p>
<p>Finally, we need a way to compute <span class="math inline">\(p(c|\mathbf{A})\)</span>. In other words, after seeing Rue make a choice, what was the probability of <em>anyone</em> with <em>any preferences</em> making that choice?</p>
<p><a href="bayes.html#normalization">Previously</a>, we got around computing denominators like this by normalizing. This works when you can enumerate the full hypothesis space. This time, the space of hypotheses (all possible assignments of utilities to fruits) is continuous and it‚Äôs not easy to integrate over. So we need to do something else.</p>
</div>
<div id="monte-carlo" class="section level4" number="8.1.1.2">
<h4>
<span class="header-section-number">8.1.1.2</span> Monte Carlo estimation<a class="anchor" aria-label="anchor" href="#monte-carlo"><i class="fas fa-link"></i></a>
</h4>
<p>We‚Äôll use an estimation method known as <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo</a> that relies on random sampling.</p>
<p>Here‚Äôs the basic idea as it applies to our problem. We want to know the overall probability of someone in the general population making a certain choice. We don‚Äôt know what that is, but we do know the distribution of utilities in the general population. That‚Äôs the prior <span class="math inline">\(p(\mathbf{u})\)</span> we just defined. So we can get a close approximation to what we want using the following algorithm:</p>
<ol style="list-style-type: decimal">
<li>Draw a random sample <span class="math inline">\(\mathbf{u}\)</span> from <span class="math inline">\(p(\mathbf{u})\)</span>.</li>
<li>Compute <span class="math inline">\(p(c|\mathbf{u}, \mathbf{A})\)</span>.</li>
<li>Repeat many times.</li>
<li>Calculate the mean choice probability of all trials.</li>
</ol>
<p>Let‚Äôs write a function to do this.</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb90-1"><a href="social-cognition.html#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> estimate_marginal_likelihood(j, options, n_samples): </span>
<span id="cb90-2"><a href="social-cognition.html#cb90-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">'''Returns an estimate of the probability of choosing option j</span></span>
<span id="cb90-3"><a href="social-cognition.html#cb90-3" aria-hidden="true" tabindex="-1"></a><span class="co">     from the set options using Monte Carlo estimation.</span></span>
<span id="cb90-4"><a href="social-cognition.html#cb90-4" aria-hidden="true" tabindex="-1"></a><span class="co">     </span></span>
<span id="cb90-5"><a href="social-cognition.html#cb90-5" aria-hidden="true" tabindex="-1"></a><span class="co">     Parameters:</span></span>
<span id="cb90-6"><a href="social-cognition.html#cb90-6" aria-hidden="true" tabindex="-1"></a><span class="co">       j (int): the chosen option</span></span>
<span id="cb90-7"><a href="social-cognition.html#cb90-7" aria-hidden="true" tabindex="-1"></a><span class="co">       options (array): a matrix in which each row is an</span></span>
<span id="cb90-8"><a href="social-cognition.html#cb90-8" aria-hidden="true" tabindex="-1"></a><span class="co">         option, and each option is a binary array of the </span></span>
<span id="cb90-9"><a href="social-cognition.html#cb90-9" aria-hidden="true" tabindex="-1"></a><span class="co">         attributes in that option</span></span>
<span id="cb90-10"><a href="social-cognition.html#cb90-10" aria-hidden="true" tabindex="-1"></a><span class="co">       n_samples (int): number of Monte Carlo samples to</span></span>
<span id="cb90-11"><a href="social-cognition.html#cb90-11" aria-hidden="true" tabindex="-1"></a><span class="co">         collect</span></span>
<span id="cb90-12"><a href="social-cognition.html#cb90-12" aria-hidden="true" tabindex="-1"></a><span class="co">         </span></span>
<span id="cb90-13"><a href="social-cognition.html#cb90-13" aria-hidden="true" tabindex="-1"></a><span class="co">     Returns:</span></span>
<span id="cb90-14"><a href="social-cognition.html#cb90-14" aria-hidden="true" tabindex="-1"></a><span class="co">       (float): probability of choosing option j</span></span>
<span id="cb90-15"><a href="social-cognition.html#cb90-15" aria-hidden="true" tabindex="-1"></a><span class="co">  '''</span></span>
<span id="cb90-16"><a href="social-cognition.html#cb90-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb90-17"><a href="social-cognition.html#cb90-17" aria-hidden="true" tabindex="-1"></a>  n_attributes <span class="op">=</span> <span class="bu">len</span>(options[<span class="dv">0</span>])</span>
<span id="cb90-18"><a href="social-cognition.html#cb90-18" aria-hidden="true" tabindex="-1"></a>  mc_samples <span class="op">=</span> np.zeros(n_samples)</span>
<span id="cb90-19"><a href="social-cognition.html#cb90-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb90-20"><a href="social-cognition.html#cb90-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_samples):</span>
<span id="cb90-21"><a href="social-cognition.html#cb90-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># draw random u sample</span></span>
<span id="cb90-22"><a href="social-cognition.html#cb90-22" aria-hidden="true" tabindex="-1"></a>    u <span class="op">=</span> np.random.normal(u_mean,u_sd,n_attributes)</span>
<span id="cb90-23"><a href="social-cognition.html#cb90-23" aria-hidden="true" tabindex="-1"></a>    mc_samples[i] <span class="op">=</span> compute_choice_prob(j, u, options)</span>
<span id="cb90-24"><a href="social-cognition.html#cb90-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb90-25"><a href="social-cognition.html#cb90-25" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>(np.mean(mc_samples))</span></code></pre></div>
<p>Let‚Äôs compare the probability of someone making <a href="social-cognition.html#inverting-the-choice-model">the choices that Rue and Jules made</a>.</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb91-1"><a href="social-cognition.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Rue's choice probability: "</span> <span class="op">+</span> </span>
<span id="cb91-2"><a href="social-cognition.html#cb91-2" aria-hidden="true" tabindex="-1"></a>  <span class="bu">str</span>(estimate_marginal_likelihood(<span class="dv">0</span>, choice_rue, <span class="dv">2000</span>)))</span></code></pre></div>
<pre><code>## Rue's choice probability: 0.9722552429060991</code></pre>
<div class="sourceCode" id="cb93"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb93-1"><a href="social-cognition.html#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Jules's choice probability: "</span> <span class="op">+</span></span>
<span id="cb93-2"><a href="social-cognition.html#cb93-2" aria-hidden="true" tabindex="-1"></a>  <span class="bu">str</span>(estimate_marginal_likelihood(<span class="dv">0</span>, choice_jules, <span class="dv">2000</span>)))</span></code></pre></div>
<pre><code>## Jules's choice probability: 0.028287781680500126</code></pre>
<p>Unsurprisingly, Jules‚Äôs choice has a much higher baseline probability.</p>
</div>
<div id="putting-it-all-together" class="section level4" number="8.1.1.3">
<h4>
<span class="header-section-number">8.1.1.3</span> Putting it all together<a class="anchor" aria-label="anchor" href="#putting-it-all-together"><i class="fas fa-link"></i></a>
</h4>
<p>Now we‚Äôll infer Rue‚Äôs and Jules‚Äôs preferences from their choices using Monte Carlo estimation again.</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb95-1"><a href="social-cognition.html#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random state for reproducibility</span></span>
<span id="cb95-2"><a href="social-cognition.html#cb95-2" aria-hidden="true" tabindex="-1"></a>np.random.RandomState(<span class="dv">2022</span>) </span></code></pre></div>
<pre><code>## RandomState(MT19937) at 0x20707B5F540</code></pre>
<div class="sourceCode" id="cb97"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb97-1"><a href="social-cognition.html#cb97-1" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">2000</span> <span class="co"># number of Monte Carlo samples</span></span>
<span id="cb97-2"><a href="social-cognition.html#cb97-2" aria-hidden="true" tabindex="-1"></a>n_attributes <span class="op">=</span> <span class="bu">len</span>(choice_rue[<span class="dv">0</span>])</span>
<span id="cb97-3"><a href="social-cognition.html#cb97-3" aria-hidden="true" tabindex="-1"></a>peach <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb97-4"><a href="social-cognition.html#cb97-4" aria-hidden="true" tabindex="-1"></a>banana <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb97-5"><a href="social-cognition.html#cb97-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-6"><a href="social-cognition.html#cb97-6" aria-hidden="true" tabindex="-1"></a>marginal_likelihood_rue <span class="op">=</span> estimate_marginal_likelihood(<span class="dv">0</span>, choice_rue, n_samples)</span>
<span id="cb97-7"><a href="social-cognition.html#cb97-7" aria-hidden="true" tabindex="-1"></a>marginal_likelihood_jules <span class="op">=</span> estimate_marginal_likelihood(<span class="dv">0</span>, choice_jules, n_samples)</span>
<span id="cb97-8"><a href="social-cognition.html#cb97-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-9"><a href="social-cognition.html#cb97-9" aria-hidden="true" tabindex="-1"></a>mc_samples_rue <span class="op">=</span> np.zeros(n_samples)</span>
<span id="cb97-10"><a href="social-cognition.html#cb97-10" aria-hidden="true" tabindex="-1"></a>mc_samples_jules <span class="op">=</span> np.zeros(n_samples)</span>
<span id="cb97-11"><a href="social-cognition.html#cb97-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-12"><a href="social-cognition.html#cb97-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_samples):</span>
<span id="cb97-13"><a href="social-cognition.html#cb97-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Draw u samples for Rue and Jules</span></span>
<span id="cb97-14"><a href="social-cognition.html#cb97-14" aria-hidden="true" tabindex="-1"></a>  u_rue <span class="op">=</span> np.random.normal(u_mean,u_sd,n_attributes)</span>
<span id="cb97-15"><a href="social-cognition.html#cb97-15" aria-hidden="true" tabindex="-1"></a>  u_jules <span class="op">=</span> np.random.normal(u_mean,u_sd,n_attributes)</span>
<span id="cb97-16"><a href="social-cognition.html#cb97-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb97-17"><a href="social-cognition.html#cb97-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute posterior for peach utility for each person</span></span>
<span id="cb97-18"><a href="social-cognition.html#cb97-18" aria-hidden="true" tabindex="-1"></a>  pu_rue <span class="op">=</span> ((compute_choice_prob(<span class="dv">0</span>, u_rue, choice_rue) <span class="op">*</span> u_rue) <span class="op">/</span> </span>
<span id="cb97-19"><a href="social-cognition.html#cb97-19" aria-hidden="true" tabindex="-1"></a>    marginal_likelihood_rue)</span>
<span id="cb97-20"><a href="social-cognition.html#cb97-20" aria-hidden="true" tabindex="-1"></a>  pu_jules <span class="op">=</span> ((compute_choice_prob(<span class="dv">0</span>, u_jules, choice_jules) <span class="op">*</span> u_jules) <span class="op">/</span></span>
<span id="cb97-21"><a href="social-cognition.html#cb97-21" aria-hidden="true" tabindex="-1"></a>    marginal_likelihood_jules)</span>
<span id="cb97-22"><a href="social-cognition.html#cb97-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-23"><a href="social-cognition.html#cb97-23" aria-hidden="true" tabindex="-1"></a>  mc_samples_rue[i] <span class="op">=</span> pu_rue[peach]</span>
<span id="cb97-24"><a href="social-cognition.html#cb97-24" aria-hidden="true" tabindex="-1"></a>  mc_samples_jules[i] <span class="op">=</span> pu_jules[peach]</span></code></pre></div>
<p>Let‚Äôs look at the results.</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb98-1"><a href="social-cognition.html#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb98-2"><a href="social-cognition.html#cb98-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sb</span>
<span id="cb98-3"><a href="social-cognition.html#cb98-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-4"><a href="social-cognition.html#cb98-4" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> pd.DataFrame(data <span class="op">=</span> {<span class="st">'Rue'</span>: mc_samples_rue,</span>
<span id="cb98-5"><a href="social-cognition.html#cb98-5" aria-hidden="true" tabindex="-1"></a>                               <span class="st">'Jules'</span>: mc_samples_jules})</span>
<span id="cb98-6"><a href="social-cognition.html#cb98-6" aria-hidden="true" tabindex="-1"></a><span class="co"># reorganize the data</span></span>
<span id="cb98-7"><a href="social-cognition.html#cb98-7" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> samples.melt(value_vars<span class="op">=</span>[<span class="st">"Jules"</span>,<span class="st">"Rue"</span>], </span>
<span id="cb98-8"><a href="social-cognition.html#cb98-8" aria-hidden="true" tabindex="-1"></a>  var_name<span class="op">=</span><span class="st">"person"</span>, value_name<span class="op">=</span><span class="st">"u"</span>)</span>
<span id="cb98-9"><a href="social-cognition.html#cb98-9" aria-hidden="true" tabindex="-1"></a><span class="co"># filter out extreme samples</span></span>
<span id="cb98-10"><a href="social-cognition.html#cb98-10" aria-hidden="true" tabindex="-1"></a>samples_filtered <span class="op">=</span> samples[samples[<span class="st">"u"</span>] <span class="op">&lt;</span> <span class="dv">50</span>]</span>
<span id="cb98-11"><a href="social-cognition.html#cb98-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-12"><a href="social-cognition.html#cb98-12" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb98-13"><a href="social-cognition.html#cb98-13" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> sb.displot(data<span class="op">=</span>samples_filtered, x<span class="op">=</span><span class="st">"u"</span>, hue<span class="op">=</span><span class="st">"person"</span>, kind<span class="op">=</span><span class="st">"kde"</span>)</span>
<span id="cb98-14"><a href="social-cognition.html#cb98-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-15"><a href="social-cognition.html#cb98-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="inline-figure"><img src="_main_files/figure-html/unnamed-chunk-67-13.png" width="558"></div>
<p>The model‚Äôs inferences here require some interpretation. The model is more certain about Rue having a preference for peach, but the distribution on the Jules‚Äôs preference for peach has a much longer tail.</p>
<p>This makes some sense. Because of our mostly positive prior distribution, it‚Äôs reasonable to assume by default that Rue likes peaches.</p>
<p>Jules‚Äôs choice is a bit odd, so it‚Äôs harder to make sense of. One way to explain it is that she simply made a mistake (after all, <a href="social-cognition.html#monte-carlo">as we saw above</a>, it‚Äôs an improbable choice). Another way to explain it is by assuming she has a very strong preference for peaches. (Of course, the model doesn‚Äôt take into account the countless other reasons Jules might prefer one fruit over three.)</p>
</div>
</div>
<div id="homework-5-your-turn" class="section level3" number="8.1.2">
<h3>
<span class="header-section-number">8.1.2</span> Homework 5: Your turn<a class="anchor" aria-label="anchor" href="#homework-5-your-turn"><i class="fas fa-link"></i></a>
</h3>
<p><a href="https://colab.research.google.com/drive/1Zk2mUWffNXrBd_9S_7FqD8KDCr9-CofY?usp=sharing"><img src="https://colab.research.google.com/assets/colab-badge.svg"></a></p>
<p>In your next assignment, you‚Äôll fully implement a version of this model and compare it to data I collected (along with Chris Lucas and Charles Kemp).</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-68"></span>
<img src="images/08/cards.jpg" alt="Cards used in the preference learning task from Jern, Lucas, &amp; Kemp (2017)." width="75%"><p class="caption">
Figure 8.1: Cards used in the preference learning task from Jern, Lucas, &amp; Kemp (2017).
</p>
</div>
</div>
</div>
<div id="na√Øve-utility-calculus" class="section level2" number="8.2">
<h2>
<span class="header-section-number">8.2</span> Na√Øve utility calculus üßÆ<a class="anchor" aria-label="anchor" href="#na%C3%AFve-utility-calculus"><i class="fas fa-link"></i></a>
</h2>
<p>Suppose Rue and Jules both make a choice between the same two fruits:</p>
<blockquote>
<p>Option 1: üçë</p>
<p>Option 2: üçå</p>
</blockquote>
<p>They both choose the peach üçë. The difference is that, for Rue, both fruits were placed in a bowl in front of her. For Jules, the peach was in a bowl in front her, and the banana was on a high shelf in another room.</p>
<p>In both cases, you‚Äôd probably assume they like peaches, but you might conclude there‚Äôs weaker evidence that Jules likes them. She may have chosen the peach because it was just convenient.</p>
<p>This (pretty contrived) example shows how people‚Äôs choices are a function of both <em>rewards</em> (or preferences) and <em>costs</em>. And when we‚Äôre thinking about other people‚Äôs behavior, we take their potential rewards and costs into account to understand why they‚Äôre doing things.</p>
<p>This idea was best articulated and formalized by <a href="https://compdevlab.yale.edu/docs/Jara-EttingerGweonShulzTenenbaum_TiCS.pdf">Julian Jara-Ettinger and his collaborators</a>. And they incorporated it into a computational model.</p>
<p>Specifically, suppose a person has a plan <span class="math inline">\(p\)</span> to achieve an outcome <span class="math inline">\(o\)</span>. We can define their utility <span class="math inline">\(U\)</span> as:</p>
<p><span class="math display">\[
U(o,p) = R(o) - C(p)
\]</span></p>
<p>where <span class="math inline">\(R(\cdot)\)</span> is their reward from the outcome and <span class="math inline">\(C(\cdot)\)</span> is the cost they incur from carrying out the plan.</p>
<div id="markov-decision-processes" class="section level3" number="8.2.1">
<h3>
<span class="header-section-number">8.2.1</span> Markov decision processes<a class="anchor" aria-label="anchor" href="#markov-decision-processes"><i class="fas fa-link"></i></a>
</h3>
<p>Earlier, we considered single decisions that happened in isolation. But lots of behavior involves a series of small decisions that happen in a sequence: the order in which someone prepares and cooks a dish, the route someone takes to get from their workplace to their home, which sections of a book chapter they write first.</p>
<p>A series of decisions is a plan <span class="math inline">\(p\)</span>. And a useful computational framework for choosing optimal plans is a <a href="https://en.wikipedia.org/wiki/Markov_decision_process">Markov decision process</a>.</p>
<p>To be concrete, let‚Äôs focus on the specific environment in <a href="https://compdevlab.yale.edu/docs/2020/cogpsych_NUC.pdf">Jara-Ettinger et al (2020)</a>: a 7x7 grid in which agents can move in any direction, one step at a time.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-69"></span>
<img src="images/08/jara-ettinger-grid.png" alt="Example of a grid and an agent path from Jara-Ettinger et al (2020)." width="60%"><p class="caption">
Figure 8.2: Example of a grid and an agent path from Jara-Ettinger et al (2020).
</p>
</div>
<p>The locations in the grid are states <span class="math inline">\(S\)</span>. Whenever an agent is in a state <span class="math inline">\(s\)</span>, they can take an action <span class="math inline">\(a \in A\)</span>, moving to any adjacent state. The agent has some goal state in mind (in the figure above, it‚Äôs the green square). What we want is an optimal <em>policy</em> that takes a state and returns an optimal action for getting toward the goal state. This can be computed as follows.</p>
<p>First, we compute each state‚Äôs optimal value <span class="math inline">\(V^*(s)\)</span>, using this recursive equation:</p>
<p><span class="math display">\[
V^*(s) = \text{max}_a\gamma \sum_{s^\prime} P_{s,a}(s^\prime) V^*(s^\prime) + R(a,s) - C(a,s)
\]</span></p>
<p>where <span class="math inline">\(P_{s,a}(s^\prime)\)</span> is ‚Äúthe probability that the agent will be in state <span class="math inline">\(s^\prime\)</span> when she takes action <span class="math inline">\(a\)</span> in state <span class="math inline">\(s\)</span> and <span class="math inline">\(\gamma \in {0,1}\)</span>.‚Äù</p>
<p>Essentially, this equation requires going through every state in the grid, summing up its rewards and costs, plus the expected downstream rewards and costs of that state.</p>
<p>Solving this recursive function is outside the scope of this book, but there are standard methods for doing it and even <a href="https://pymdptoolbox.readthedocs.io/en/latest/index.html">Python packages</a> for solving MDPs.</p>
<p>The action policy is then defined as:</p>
<p><span class="math display" id="eq:optimalpolicy">\[
\begin{equation}
p(a|s) \propto \exp \left( \sum_{s^\prime} P_{s,a}(s^\prime) V^*(s^\prime) \right)
\tag{8.3}
\end{equation}
\]</span>
In their model, they once again introduce a notion of a ‚Äúsoftmax‚Äù choice rule, rather than assume agents will be perfectly optimal. This makes sense because the goal is to model how people reason about others, and people often have incomplete information about other people.</p>
</div>
<div id="inverting-the-mdp" class="section level3" number="8.2.2">
<h3>
<span class="header-section-number">8.2.2</span> Inverting the MDP<a class="anchor" aria-label="anchor" href="#inverting-the-mdp"><i class="fas fa-link"></i></a>
</h3>
<p>After seeing an agent take a series of actions <span class="math inline">\(\mathbf{a}\)</span>, we can infer their costs and rewards pretty much the same way we did before, by applying Bayes‚Äôs rule.</p>
<p><span class="math display">\[
p(C,R|\mathbf{a}) \propto p(\mathbf{a}|C,R) p(C,R)
\]</span></p>
<p>In the model, they use uniform priors over costs and rewards. Computing <span class="math inline">\(p(\mathbf{a}|C,R)\)</span> means just applying Equation <a href="social-cognition.html#eq:optimalpolicy">(8.3)</a> repeatedly for each action the agent took in their sequence. (The researchers also modeled a notion of sub-goals that I‚Äôve omitted.)</p>
</div>
<div id="results-1" class="section level3" number="8.2.3">
<h3>
<span class="header-section-number">8.2.3</span> Results<a class="anchor" aria-label="anchor" href="#results-1"><i class="fas fa-link"></i></a>
</h3>
<p>The researchers tested their model in a series of experiments in which people saw paths that agents took across the grid and then had to rate the costs and rewards the agent assigned to different states.</p>
<p>Results from one experiment are below.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-70"></span>
<img src="images/08/jara-ettinger-results.png" alt="Partial results from Experiment 1b of Jara-Ettinger et al (2020)." width="90%"><p class="caption">
Figure 8.3: Partial results from Experiment 1b of Jara-Ettinger et al (2020).
</p>
</div>
<p>The cost and reward ratings were separately normalized so that they had a mean of zero. Then they were combined in the plots.</p>
<p>Compared to simpler alternative models, the full na√Øve utility calculus model provided the best fit to people‚Äôs judgments.</p>

</div>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="pragmatics.html"><span class="header-section-number">7</span> Language pragmatics</a></div>
<div class="next"><a href="iterated-learning.html"><span class="header-section-number">9</span> Iterated learning</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#social-cognition"><span class="header-section-number">8</span> Social cognition</a></li>
<li>
<a class="nav-link" href="#inverse-decision-making"><span class="header-section-number">8.1</span> Inverse decision-making üçë</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#a-preference-learning-model"><span class="header-section-number">8.1.1</span> A preference learning model</a></li>
<li><a class="nav-link" href="#homework-5-your-turn"><span class="header-section-number">8.1.2</span> Homework 5: Your turn</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#na%C3%AFve-utility-calculus"><span class="header-section-number">8.2</span> Na√Øve utility calculus üßÆ</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#markov-decision-processes"><span class="header-section-number">8.2.1</span> Markov decision processes</a></li>
<li><a class="nav-link" href="#inverting-the-mdp"><span class="header-section-number">8.2.2</span> Inverting the MDP</a></li>
<li><a class="nav-link" href="#results-1"><span class="header-section-number">8.2.3</span> Results</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/alanjern/computational-psych-book/blob/main/08-social-cognition.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/alanjern/computational-psych-book/edit/main/08-social-cognition.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Introduction to Computational Psychology</strong>" was written by Alan Jern. It was last built on 2022-04-21.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
