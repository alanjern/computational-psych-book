<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="An introduction to computational cognitive science with a focus on probabilistic modeling. Code and exercises in Python.">

<title>Introduction to Computational Psychology - 10&nbsp; Causal inference</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./09-iterated-learning.html" rel="prev">
<link href="./images/favicons/favicon-32x32.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="twitter:title" content="Introduction to Computational Psychology - 10&nbsp; Causal inference">
<meta name="twitter:description" content="An introduction to computational cognitive science with a focus on probabilistic modeling. Code and exercises in Python.">
<meta name="twitter:image" content="images/cover/marble_notext.jpg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./10-causal-inference.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Causal inference</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introduction to Computational Psychology</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/alanjern/computational-psych-book" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Why computational modeling?</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bayesian inference</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-generalization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Generalization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-categorization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Categorization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-hierarchical-bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Hierarchical generalization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-sampling-assumptions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Sampling assumptions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-RSA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Language pragmatics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-social-cognition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Social cognition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-iterated-learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Iterated learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-causal-inference.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Causal inference</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#bayes-nets" id="toc-bayes-nets" class="nav-link active" data-scroll-target="#bayes-nets"><span class="header-section-number">10.1</span> Bayes nets ➡️</a></li>
  <li><a href="#causal-intervention" id="toc-causal-intervention" class="nav-link" data-scroll-target="#causal-intervention"><span class="header-section-number">10.2</span> Causal intervention 🪚</a>
  <ul class="collapse">
  <li><a href="#graph-surgery" id="toc-graph-surgery" class="nav-link" data-scroll-target="#graph-surgery"><span class="header-section-number">10.2.1</span> Graph surgery</a></li>
  <li><a href="#do-people-intuitively-understand-the-logic-of-casual-intervention" id="toc-do-people-intuitively-understand-the-logic-of-casual-intervention" class="nav-link" data-scroll-target="#do-people-intuitively-understand-the-logic-of-casual-intervention"><span class="header-section-number">10.2.2</span> Do people intuitively understand the logic of casual intervention?</a></li>
  </ul></li>
  <li><a href="#structure-strength" id="toc-structure-strength" class="nav-link" data-scroll-target="#structure-strength"><span class="header-section-number">10.3</span> Causal structure and strength 🏗💪</a>
  <ul class="collapse">
  <li><a href="#the-causal-support-model" id="toc-the-causal-support-model" class="nav-link" data-scroll-target="#the-causal-support-model"><span class="header-section-number">10.3.1</span> The causal support model</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/alanjern/computational-psych-book/blob/main/10-causal-inference.qmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="causal-inference" class="quarto-section-identifier"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Causal inference</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>The world is full of weird and interesting relationships. Like this one.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/10/maine_divorce_rate.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Correlation between Maine divorce rates and per capita margarine consumption. Source: tylervigen.com.</figcaption>
</figure>
</div>
<p>Which of these weird relationships are <em>causal</em> relationships and how can we tell? (Does cutting back on margarine reduce your chances of divorce? Probably not.)</p>
<p>Causal inference is, in fact, a major area of research in statistics and machine learning. But we’ll just focus on the question of how people decide what causes what.</p>
<p>We’ll use a computational framework for making optimal probabilistic causal judgments called Bayesian networks, or <strong>Bayes nets</strong> for short. Comparing people’s judgments to Bayes net predictions allows us to see how optimal (or not) people are. Additionally, as we’ll see, Bayes nets are well suited for <em>intervention</em>, which is one way that people learn about causes.</p>
<section id="bayes-nets" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="bayes-nets"><span class="header-section-number">10.1</span> Bayes nets ➡️</h2>
<p>A Bayes net is a graph that describes the dependencies between all the variables in a situation.</p>
<p>For example, let’s make a Bayes net for the problem in Chapter 5 of <a href="05-hierarchical-bayes.html#beta-binomial">inferring the bias of a coin</a>. In that problem, there were three key variables: the bias <span class="math inline">\(\theta\)</span>, the total number of flips <span class="math inline">\(n\)</span>, and the number of heads <span class="math inline">\(k\)</span>. We can represent this as a Bayes net.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/10/beta_binomial_bayesnet1.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Bayes net representation of the coin bias problem.</figcaption>
</figure>
</div>
<p>In Bayes nets, shaded notes represent variables that are known or observed, and unshaded nodes represent variables that are unknown. We know how many times the coin was flipped and came up heads, but we don’t directly know the bias <span class="math inline">\(\theta\)</span>.</p>
<p>We could extend this Bayes net to capture the <em>generalization</em> problem of predicting the outcome of the next coin flip <span class="math inline">\(x\)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/10/beta_binomial_bayesnet2.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Bayes net representation of the biased coin generalization problem.</figcaption>
</figure>
</div>
<p>A complete Bayes net also specifies a probability distribution for each variable. In the example above, <span class="math inline">\(k\)</span> is a function of <span class="math inline">\(\theta\)</span> and <span class="math inline">\(n\)</span>. As we learned in <a href="05-hierarchical-bayes.html#beta-binomial">Chapter 5</a>, this is a Binomial distribution. We also need to specify a prior probability over any unknown variables, like <span class="math inline">\(\theta\)</span>. Previously we assumed it was distributed according to a Beta distribution. <span class="math inline">\(x\)</span> is just a single coin flip – it’s a special case of a Binomial distribution called a Bernoulli distribution in which <span class="math inline">\(n = 1\)</span>. To sum up:</p>
<ul>
<li><span class="math inline">\(\theta \sim \text{Beta}(\alpha, \beta)\)</span></li>
<li><span class="math inline">\(k \sim \text{Binomial}(n,\theta)\)</span></li>
<li><span class="math inline">\(x \sim \text{Binomial}(n=1, \theta)\)</span></li>
</ul>
</section>
<section id="causal-intervention" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="causal-intervention"><span class="header-section-number">10.2</span> Causal intervention 🪚</h2>
<p>Consider the following two Bayes nets.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/10/three_var_nets.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Two Bayes nets with three variables.</figcaption>
</figure>
</div>
<p>To be concrete, let’s say that variables <span class="math inline">\(s\)</span> and <span class="math inline">\(x\)</span> represent levels of hormones sonin and xanthan, respectively. Variable <span class="math inline">\(z\)</span> is an unknown variable.</p>
<p>The <em>common cause</em> network is so-called because sonin (<span class="math inline">\(s\)</span>) and xanthan (<span class="math inline">\(x\)</span>) are both causally dependent on <span class="math inline">\(z\)</span>. The <em>chain</em> network is so-called because all the variables form a causal chain from <span class="math inline">\(s\)</span> to <span class="math inline">\(x\)</span> to <span class="math inline">\(z\)</span>. (Note the directions of the arrows in the two Bayes nets.)</p>
<p>Let’s see what kind of data these Bayes nets produce. Let’s assume that each root node of a network (<span class="math inline">\(z\)</span> in the common cause, <span class="math inline">\(x\)</span> in the chain) follows a normal distribution with mean 0 and SD 1. Each link in a network follows a normal distribution with mean equal to the value of its parent node and SD 1.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Common cause</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>z_mu <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>sd <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>z_samples_cc <span class="op">=</span> np.zeros(n_samples)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>s_samples_cc <span class="op">=</span> np.zeros(n_samples)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>x_samples_cc <span class="op">=</span> np.zeros(n_samples)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_samples):</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  z_samples_cc[i] <span class="op">=</span> np.random.normal(z_mu, sd)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  s_samples_cc[i] <span class="op">=</span> np.random.normal(z_samples_cc[i], sd)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>  x_samples_cc[i] <span class="op">=</span> np.random.normal(s_samples_cc[i], sd)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Chain</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>x_mu <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>z_samples_chain <span class="op">=</span> np.zeros(n_samples)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>s_samples_chain <span class="op">=</span> np.zeros(n_samples)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>x_samples_chain <span class="op">=</span> np.zeros(n_samples)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_samples):</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>  x_samples_chain[i] <span class="op">=</span> np.random.normal(x_mu, sd)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>  z_samples_chain[i] <span class="op">=</span> np.random.normal(x_samples_chain[i], sd)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>  s_samples_chain[i] <span class="op">=</span> np.random.normal(z_samples_chain[i], sd)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Because <span class="math inline">\(z\)</span> represents an unknown variable, let’s plot just <span class="math inline">\(s\)</span> and <span class="math inline">\(x\)</span>.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>ax1.scatter(s_samples_cc, x_samples_cc, alpha <span class="op">=</span> <span class="fl">0.1</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">"s"</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">"x"</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">"Common cause"</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>ax2.scatter(s_samples_chain, x_samples_chain, alpha <span class="op">=</span> <span class="fl">0.1</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">"s"</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">"Chain"</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="10-causal-inference_files/figure-html/cell-3-output-1.png" width="587" height="449"></p>
</div>
</div>
<p>Clearly, the data isn’t identical in the two cases, but data generated by both Bayes nets results in a strong positive correlation between <span class="math inline">\(s\)</span> and <span class="math inline">\(x\)</span>.</p>
<p>Imagine you didn’t know how this data was generated and you just got one of these plots. Could you use it to tell whether it was produced by a common cause structure or a chain structure?</p>
<p>Sorry, but no. 😔 Just knowing the data are positively correlated doesn’t give you enough information to figure out how <span class="math inline">\(s\)</span> and <span class="math inline">\(x\)</span> are causally related.</p>
<p>But what if you could manipulate the variables? That is, what if you could <em>intervene</em> on sonin levels and see what effect it had on xanthan levels?</p>
<ul>
<li>If you increase the sonin levels 📈 and the xanthan levels also increase 📈, then the causal structure must be a chain.</li>
<li>If you increase the sonin levels 📈 and the xanthan levels don’t change ❌, then the causal structure can’t be a chain (and therefore must be a common cause, because that’s the only other option we’re considering).</li>
</ul>
<section id="graph-surgery" class="level3" data-number="10.2.1">
<h3 data-number="10.2.1" class="anchored" data-anchor-id="graph-surgery"><span class="header-section-number">10.2.1</span> Graph surgery</h3>
<p>This intuition can be illustrated visually on the Bayes nets by performing “surgery” on the graphs. It works like this:</p>
<ol type="1">
<li>Remove all incoming connections to the variable you’re intervening on.</li>
<li>If there’s still a path between the variable you intervened on and another variable, then you should still expect those variables to be related.</li>
</ol>
<p>Let’s apply this idea to our common cause and chain Bayes nets.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/10/graph_surgery.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Graph surgery applied to the common cause and chain Bayes nets. The invervention is indicated by the red arrow.</figcaption>
</figure>
</div>
<p>After intervening on sonin levels (<span class="math inline">\(s\)</span>), we remove the connection to <span class="math inline">\(s\)</span> in the common cause network, but no connections in the chain network. The resulting Bayes nets show why we should expect to see a resulting change in xanthan for the chain, but not the common cause.</p>
</section>
<section id="do-people-intuitively-understand-the-logic-of-casual-intervention" class="level3" data-number="10.2.2">
<h3 data-number="10.2.2" class="anchored" data-anchor-id="do-people-intuitively-understand-the-logic-of-casual-intervention"><span class="header-section-number">10.2.2</span> Do people intuitively understand the logic of casual intervention?</h3>
<p><a href="https://psycnet.apa.org/doi/10.1037/0278-7393.31.2.216">A study by Michael Waldmann and York Hagmayer</a> presented people with either the common cause or the chain structure. They were told that sonin and xanthan were hormone levels in chimps and they got some example data that allowed them to learn that the hormone levels were positively correlated.</p>
<p>Then they were either assigned to a <em>doing</em> or <em>seeing</em> condition. People in the doing condition were asked to imagine that 20 chimps had their sonin levels raised (or lowered). They then predicted how many of the chimps would have elevated xanthan levels. People in the seeing condition got essentially the same information but just learned that the chimps’ sonin levels were high (not that it had been intentionally raised).</p>
<p>Average results and model predictions are below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/10/waldmann_hagmayer_results.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Results from Waldmann &amp; Hagmayer (2005), Experiment 2.</figcaption>
</figure>
</div>
<p>People’s judgments mostly followed those of the Bayes net model predictions. In the common cause case, when the sonin levels are artificially raised, the relationship between sonin and xanthan is decoupled, so the model reverts to a base rate prediction about xanthan levels (and so did people, for the most part). But when just observing elevated sonin levels, the model should expect the positive relationship to hold.</p>
<p>In the chain case, the predictions are the same for seeing or doing, because intervening doesn’t change anything about the relationship between sonin and xanthan. People’s judgments indicate that they understood this.</p>
</section>
</section>
<section id="structure-strength" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="structure-strength"><span class="header-section-number">10.3</span> Causal structure and strength 🏗💪</h2>
<p>Bayes nets can also account for how people judge the strength of evidence for a causal relationship after seeing some data. This was the idea that Tom Griffiths and Josh Tenenbaum explored in <a href="https://cocosci.princeton.edu/tom/papers/causal4.pdf">a 2005 computational study</a>.</p>
<p>Here’s the basic problem they considered. Suppose researchers perform an experiment with rats to test whether a drug causes a gene to be expressed. A control group of rats doesn’t get the injection and the experimental group does. They record the number of rats in each group that express the gene.</p>
<p>Here are some possible results from an experiment with 8 rats in each group. The table shows how many rats in each group expressed the gene.</p>
<table class="table">
<thead>
<tr class="header">
<th>Control 🐀</th>
<th>Experimental 🐀</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>6/8 🧬</td>
<td>8/8 🧬</td>
</tr>
<tr class="even">
<td>4/8 🧬</td>
<td>6/8 🧬</td>
</tr>
<tr class="odd">
<td>2/8 🧬</td>
<td>4/8 🧬</td>
</tr>
<tr class="even">
<td>0/8 🧬</td>
<td>2/8 🧬</td>
</tr>
</tbody>
</table>
<p>In each of these hypothetical experiments, how strongly would you say that the drug causes the gene to be expressed?</p>
<p>These are a few of the cases that were included in an experiment conducted by Marc Buehner and Patricia Cheng. Here’s the full set of averaged human results.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/10/buehner_cheng_results.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Results from Buehner &amp; Cheng (1997), Experiment 1B, reproduced by Griffiths &amp; Tenenbaum (2005). p(e+|c+) is the probability of the effect being present (e.g., the gene being expressed) given that the cause is present (e.g., the drug was administered). p(e+|c-) means the probability of the effect being present given that the cause is absent.</figcaption>
</figure>
</div>
<p>Focusing just on the cases in the table, on average, people judged that the drug was less likely to have a causal effect on the gene as the total number of rats expressing the gene decreased, even when the difference in number of rats expressing the gene between conditions was held constant.</p>
<section id="the-causal-support-model" class="level3" data-number="10.3.1">
<h3 data-number="10.3.1" class="anchored" data-anchor-id="the-causal-support-model"><span class="header-section-number">10.3.1</span> The causal support model</h3>
<p>Maybe people reason about these problems by performing a kind of model selection between the two Bayes nets below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/10/griffiths_tenenbaum_graphs.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Causal inference as model selection. In one model, there is a connection from the potential cause to the effect; in the other, the two variables are unconnected. (Image from Griffiths &amp; Tenenbaum (2005).)</figcaption>
</figure>
</div>
<p>These Bayes nets each have three variables: an effect <span class="math inline">\(E\)</span>, a cause <span class="math inline">\(C\)</span>, and a background cause <span class="math inline">\(B\)</span>. For our problem, the effect and cause refer to the gene and the drug. The inclusion of the background cause is to account for unknown factors that might cause the gene to be expressed without the drug.</p>
<p>The problem people are faced with is deciding which of these two models is best supported by the data <span class="math inline">\(D\)</span> – the number of times the effect occurred with and without the potential cause.</p>
<p>This can be done with Bayesian inference:</p>
<p><span class="math display">\[
P(\text{Graph } i) \propto P(D|\text{Graph } i) P(\text{Graph } i)
\]</span></p>
<p>Because there are only two possible networks, we can compute the relative evidence for one Bayes net over the other as a ratio. We can then take the log of the expression to simplify it:</p>
<p><span class="math display">\[
\log \frac{P(\text{Graph } 1|D)}{P(\text{Graph } 0|D)} = \log \frac{P(D | \text{Graph } 1)}{P(D | \text{Graph } 0)} + \log \frac{P(\text{Graph } 1)}{P(\text{Graph } 0)}
\]</span></p>
<p>Regardless of what prior probabilities we assign to the two graphs, the relative evidence for one graph over the other is entirely determined by the log-likelihood ratio. This is defined as <strong>causal support</strong>: <span class="math inline">\(\log \frac{P(D | \text{Graph } 1)}{P(D | \text{Graph } 0)}\)</span>.</p>
<p>Computing <span class="math inline">\(P(D | \text{Graph } 1)\)</span> requires fully specifying the Bayes net. We’ll assume that <span class="math inline">\(P(E|B) = w_0\)</span> and <span class="math inline">\(P(E|C) = w_1\)</span>. When both <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> are present, we’ll assume they contribute independently to causing <span class="math inline">\(E\)</span>, and therefore operate like a probabilistic OR function:</p>
<p><span class="math display">\[
P(e^+|b,c; w_o, w_1) = 1 - (1-w_0)^b (1-w_1)^c
\]</span></p>
<p>Here, when the B or C are present, <span class="math inline">\(b\)</span> and <span class="math inline">\(c\)</span> are set to 1, and when they are absent, <span class="math inline">\(b\)</span> and <span class="math inline">\(c\)</span> are set to 0.</p>
<p>The likelihood for Graph 1 is therefore</p>
<p><span class="math display">\[
P(D | w_0, w_1, \text{Graph } 1) = \prod_{e,c} P(e|b^+,c; w_o, w_1)^{N(e,c)}
\]</span></p>
<p>where the product is over the possible settings of <span class="math inline">\(e\)</span> and <span class="math inline">\(c\)</span> (effect absent/cause absent, effect absent/cause present, …) and the <span class="math inline">\(N(e,c)\)</span> values are counts of times that these outcomes happened in the data <span class="math inline">\(D\)</span>.</p>
<p>Here’s a function to compute this.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_likelihood(data, w0, w1, graph):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">'''Returns likelihood of data for a given graph</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">     </span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">     Parameters:</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">       data (list): observation counts in this order:</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">         N(c-,e-), N(c-,e+), N(c+,e-), N(c+,e+)</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">       w0 (float): probability of background cause producing effect</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co">       w1 (float): probability of cause of interest producing effect</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co">       graph (int): 0 (Graph 0) or 1 (Graph 1)</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co">     Returns:</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co">       (float): probability of data</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co">  '''</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> graph <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># e-</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> (<span class="dv">1</span><span class="op">-</span>w0)<span class="op">**</span>(data[<span class="dv">0</span>]<span class="op">+</span>data[<span class="dv">2</span>])</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># e+</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> p <span class="op">*</span> w0<span class="op">**</span>(data[<span class="dv">1</span>]<span class="op">+</span>data[<span class="dv">3</span>])</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">elif</span> graph <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># c-, e-</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> (<span class="dv">1</span><span class="op">-</span>w0)<span class="op">**</span>data[<span class="dv">0</span>]</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># c-, e+</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> p <span class="op">*</span> w0<span class="op">**</span>data[<span class="dv">1</span>]</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># c+, e-</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> p <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> (w0 <span class="op">+</span> w1 <span class="op">-</span> w0<span class="op">*</span>w1))<span class="op">**</span>data[<span class="dv">2</span>]</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># c+, e+</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> p <span class="op">*</span> (w0 <span class="op">+</span> w1 <span class="op">-</span> w0<span class="op">*</span>w1)<span class="op">**</span>data[<span class="dv">3</span>]</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>:</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># error!</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(<span class="dv">0</span>)</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>(p)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Causal support doesn’t actually depend directly on the parameters <span class="math inline">\(w_0\)</span> and <span class="math inline">\(w_1\)</span>. The reason is that we ultimately don’t care what the values of these parameters are because we just want to draw an inference at a higher level about the best-fitting Bayes net.</p>
<p>Mathematically speaking, <span class="math inline">\(w_0\)</span> and <span class="math inline">\(w_1\)</span> are averaged out of the model, an idea we first saw in <a href="03-generalization.html#generalizing">Chapter 3</a>. We can accomplish this using Monte Carlo approximation, introduced in <a href="08-social-cognition.html#monte-carlo">Chapter 8</a>.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> estimate_likelihood(graph_number, data): </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">'''Returns an estimate of the probability of observing the data</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">     under the specified graph using Monte Carlo estimation.</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">     </span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">     Parameters:</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">       graph_number (int): either 0 (Graph 0) or 1 (Graph 1)</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co">       data (list): observation counts in this order:</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">         N(c-,e-), N(c-,e+), N(c+,e-), N(c+,e+)</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co">     Returns:</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co">       (float): probability of observing data</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co">  '''</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  <span class="im">from</span> numpy.random <span class="im">import</span> default_rng</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>  n_samples <span class="op">=</span> <span class="dv">5000</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>  rng <span class="op">=</span> default_rng(<span class="dv">2022</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>  mc_samples <span class="op">=</span> np.zeros(n_samples)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_samples):</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sample values for w0 and w1 from a uniform distribution</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    w0 <span class="op">=</span> rng.random()</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    w1 <span class="op">=</span> rng.random()</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    mc_samples[i] <span class="op">=</span> compute_likelihood(data, w0, w1, graph_number)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>(<span class="dv">1</span><span class="op">/</span>n_samples <span class="op">*</span> np.<span class="bu">sum</span>(mc_samples))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally, let’s put it all together by writing a function that computes causal support.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> causal_support(data):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">'''Returns a causal support value for a given data set.</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co">     Causal support is a measure of how strongly a data</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">     set indicates that there is evidence for a causal</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co">     effect.</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">     </span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">     Parameters:</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">       data (list): observation counts in this order:</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co">         N(c-,e-), N(c-,e+), N(c+,e-), N(c+,e+)</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co">     Returns:</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co">       (float): strength of evidence for causal relationship</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co">  '''</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> (np.log(estimate_likelihood(<span class="dv">1</span>,data<span class="op">=</span>data) <span class="op">/</span> </span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>                 estimate_likelihood(<span class="dv">0</span>,data<span class="op">=</span>data)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now let’s see what the model predicts for the <a href="#structure-strength">four cases we considered earlier</a>.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>causal_support_predictions <span class="op">=</span> [causal_support([<span class="dv">2</span>,<span class="dv">6</span>,<span class="dv">0</span>,<span class="dv">8</span>]),</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>                              causal_support([<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">6</span>]),</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>                              causal_support([<span class="dv">6</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">4</span>]),</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>                              causal_support([<span class="dv">8</span>,<span class="dv">0</span>,<span class="dv">6</span>,<span class="dv">2</span>])]</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>                              </span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> [<span class="st">"6/8, 8/8"</span>, <span class="st">"4/8, 6/8"</span>, <span class="st">"2/8, 4/8"</span>, <span class="st">"0/8, 2/8"</span>]</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>ax.bar(labels, causal_support_predictions)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"Data"</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"Model prediction"</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="10-causal-inference_files/figure-html/cell-7-output-1.png" width="589" height="429"></p>
</div>
</div>
<p>The labels on the x-axis indicate the control condition counts, followed by the experimental condition counts.</p>
<p>You can see that the model’s predictions largely follow the <a href="#structure-strength">pattern in the data from earlier</a>. The model favors Graph 1 in the two leftmost cases, is essentially uncertain in the third case, and begins to think the evidence favors no causal relationship in the rightmost case.</p>
<p>The rest of the Griffiths &amp; Tenenbaum paper shows how causal support is able to capture some subtle aspects of people’s causal judgments that other models that don’t incorporate <em>both</em> structure and strength fail to capture.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./09-iterated-learning.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Iterated learning</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->



</body></html>